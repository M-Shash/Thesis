{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c296d2-6f05-444c-bfe1-86cd4b0e0635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 18:36:38.740016: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-16 18:36:38.919294: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755358598.966875 2478198 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755358598.986252 2478198 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755358599.097343 2478198 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755358599.097386 2478198 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755358599.097388 2478198 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755358599.097390 2478198 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-16 18:36:39.104518: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.server.strategy.strategy import Strategy\n",
    "from flwr.common import Context, ndarrays_to_parameters, FitIns, EvaluateIns, parameters_to_ndarrays, NDArrays\n",
    "from flwr.client import NumPyClient\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms,datasets\n",
    "from torchvision.models import  inception_v3\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import ToPILImage\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import uuid\n",
    "import warnings\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as UMAP\n",
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "from kneed import KneeLocator\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import skew, kurtosis\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import math \n",
    "import cv2 ,sys\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from tqdm import tqdm\n",
    "import clip as clip\n",
    "import torch.multiprocessing as mp\n",
    "mp.set_start_method('spawn', force=True)\n",
    "from itertools import chain\n",
    "import matplotlib.cm as cm \n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98825a0-e492-4722-a739-5edaffd46b0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"CPU\"\n",
    "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)#ViT-B/32 ViT-L/14\n",
    "target_classes = [\"basketball\",\"moving van\",\"mountain bike\",\"all-terrain bike\",\"van\",\"off-roader\"]\n",
    "text_tokens = clip.tokenize(target_classes).to(device)\n",
    "DATASET_TO_CLIP = {\n",
    "    \"basketball\": {\"basketball\"},\n",
    "    \"mountain bike\": {\"mountain bike\", \"all-terrain bike\", \"off-roader\"},\n",
    "    \"moving van\": {\"moving van\"},\n",
    "}\n",
    "with torch.no_grad():\n",
    "        text_features = clip_model.encode_text(text_tokens)\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "# === 1. Image Folder Dataset + SAM2 Segment Generation === #\n",
    "\n",
    "\n",
    "#target_classes = [\n",
    "#    \"soccer ball\",\n",
    "#    \"football\",\n",
    "#    \"football match\",\n",
    "#    \"mountain bike\",\n",
    "#    \"racing bicycle\",\n",
    "#    \"bike\",\n",
    "#    \"cornears\",\n",
    "#    \"A kernel of corn\",\n",
    "#    \"corn on the cob\",\n",
    "#    \"an ear of corn\",\n",
    "#    \"corn plant\",\n",
    "#    \"police van\",\n",
    "#    \"lionfish\",\n",
    "#    \"colorful lionfish\",\n",
    "#    \"basketball\",\n",
    "#    \"orange basketball\",\n",
    "#    \"basketball players\",\n",
    "#    \"basketball net\",\n",
    "#    \"basketball clothes\",\n",
    "#    \"van\",\n",
    "#    \"police\",\n",
    "#    \"truck\",\n",
    "#    \"car\",\n",
    "#    \"fish\",\n",
    "#    \"lion fish\",\n",
    "#    \"striped venomous fish\",\n",
    "#    \"marine fish with long spiny fins\",\n",
    "#    \"zebra-patterned reef fish\",\n",
    "#    \"fish with feather-like fins\",\n",
    "#    \"fish with fins\"\n",
    "#]\n",
    "\n",
    "def numpy_to_native(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: numpy_to_native(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [numpy_to_native(i) for i in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return [numpy_to_native(i) for i in obj]  # Convert tuples to lists for JSON\n",
    "    elif isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    else:\n",
    "        return obj\n",
    "        \n",
    "def get_bbox_from_mask(mask):\n",
    "    ys, xs = np.where(mask)\n",
    "    if len(xs) == 0 or len(ys) == 0:\n",
    "        return None  # skip empty mask\n",
    "    x0, x1 = xs.min(), xs.max()\n",
    "    y0, y1 = ys.min(), ys.max()\n",
    "    return (x0, y0, x1, y1)\n",
    "    \n",
    "\n",
    "def save_segments_with_metadata(image_id, original_label, segments, scores,bboxes, orig_img_path,output_dir, score_threshold):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    metadata = []\n",
    "\n",
    "    for i, (segment, score, bboxes) in enumerate(zip(segments, scores, bboxes)):\n",
    "        if score < score_threshold:\n",
    "            continue\n",
    "\n",
    "        original_name = os.path.splitext(os.path.basename(orig_img_path))[0]\n",
    "        seg_filename = f\"{original_name}_{i}.png\"\n",
    "        seg_path = os.path.join(output_dir, seg_filename)\n",
    "        Image.fromarray(segment).save(seg_path)\n",
    "\n",
    "        metadata.append({\n",
    "            \"segment_id\": seg_filename,\n",
    "            \"original_label\": int(original_label),\n",
    "            \"original_image_index\": int(image_id),\n",
    "            \"score\": float(score),\n",
    "            \"bbox\": bboxes,\n",
    "            \"original_image_path\": orig_img_path\n",
    "        })\n",
    "\n",
    "    meta_path = os.path.join(output_dir, \"metadata.json\")\n",
    "    if os.path.exists(meta_path):\n",
    "        with open(meta_path, \"r\") as f:\n",
    "            existing_metadata = json.load(f)\n",
    "        existing_metadata.extend(metadata)\n",
    "        metadata = existing_metadata\n",
    "\n",
    "    with open(meta_path, \"w\") as f:\n",
    "        json.dump(numpy_to_native(metadata), f, indent=2)\n",
    "\n",
    "    return meta_path\n",
    "\n",
    "\n",
    "# === 2. Segment Dataset with CLIP Filtering === #\n",
    "def ensure_pil(img):\n",
    "    if not isinstance(img, Image.Image):\n",
    "        img = Image.fromarray(img)\n",
    "    return img\n",
    "\n",
    "def clip_filter_segment(seg_img_pil):\n",
    "    \n",
    "    img_clip = clip_preprocess(seg_img_pil).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_feature = clip_model.encode_image(img_clip)\n",
    "        image_feature /= image_feature.norm(dim=-1, keepdim=True)\n",
    "        similarity = (100.0 * image_feature @ text_features.T)\n",
    "        probs = similarity.softmax(dim=-1)\n",
    "        topk = 2\n",
    "        top_scores, top_indices = torch.topk(probs, k=topk, dim=-1)\n",
    "        #best_idx = probs.argmax(dim=-1).item()\n",
    "        clip_scores = [s.item() for s in top_scores[0]]\n",
    "        class_names = [target_classes[i] for i in top_indices[0].tolist()]\n",
    "        # Empirical threshold to reduce false positives\n",
    "        #threshold = 0.5\n",
    "        return class_names, clip_scores# if clip_score >= threshold else (None, clip_score)\n",
    "\n",
    "\n",
    "class SegmentDataset(Dataset):\n",
    "    def __init__(self, segment_root, transform):\n",
    "        self.samples = []\n",
    "        self.metadata = []\n",
    "        self.total_segments = 0\n",
    "        self.clip_filtered_out = 0\n",
    "        self.transform = transform\n",
    "\n",
    "        for class_name in sorted(os.listdir(segment_root)):\n",
    "            meta_path = os.path.join(segment_root, class_name, \"metadata.json\")\n",
    "            if not os.path.exists(meta_path):\n",
    "                print(f\"[DEBUG] Metadata json missing for class: {class_name}\")\n",
    "                continue\n",
    "\n",
    "            with open(meta_path, \"r\") as f:\n",
    "                meta = json.load(f)\n",
    "\n",
    "            for entry in meta:\n",
    "                img_path = os.path.join(segment_root, class_name, entry[\"segment_id\"])\n",
    "                if not os.path.exists(img_path):\n",
    "                    print(f\"[DEBUG] Missing segment image file: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                self.total_segments += 1\n",
    "\n",
    "                # Do filtering at init time\n",
    "                try:\n",
    "                    pil_img = Image.open(img_path).convert(\"RGB\")\n",
    "                    top_classes, top_scores = clip_filter_segment(pil_img)\n",
    "                    valid_clip_classes = DATASET_TO_CLIP.get(class_name, set())\n",
    "                    valid_clip_classes_lower = {c.lower() for c in valid_clip_classes}\n",
    "                    accepted = False\n",
    "                    original_class = class_name\n",
    "                    for c, s in zip(top_classes, top_scores):\n",
    "                        if c.lower() in valid_clip_classes_lower and s >= 0.5:\n",
    "                            clip_class = c\n",
    "                            clip_score = s\n",
    "                            accepted = True\n",
    "                            break\n",
    "                    if not accepted:\n",
    "                       self.clip_filtered_out += 1\n",
    "                       continue\n",
    "                    if clip_class is None:\n",
    "                        self.clip_filtered_out += 1\n",
    "                        continue  # skip this sample\n",
    "                    \n",
    "                        \n",
    "                    entry.update({\n",
    "                        \"class_name\": class_name,\n",
    "                        \"img_path\": img_path,\n",
    "                        \"clip_class\": clip_class,\n",
    "                        \"clip_score\": clip_score\n",
    "                    })\n",
    "                    self.samples.append(img_path)\n",
    "                    self.metadata.append(entry)\n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Failed filtering {img_path}: {e}\")\n",
    "                    self.clip_filtered_out += 1\n",
    "                    continue\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.samples[idx]\n",
    "        meta = self.metadata[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = torch.tensor(meta[\"original_label\"])\n",
    "        return img, label, meta\n",
    "\n",
    "    def get_stats(self):\n",
    "        return {\n",
    "            \"total_attempted\": self.total_segments,\n",
    "            \"clip_filtered_out\": self.clip_filtered_out,\n",
    "            \"clip_passed\": len(self.samples)\n",
    "        }\n",
    "\n",
    "dino_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def custom_collate(batch):\n",
    "    batch = [item for item in batch if item is not None and all(e is not None for e in item)]\n",
    "    if not batch:\n",
    "        return torch.empty(0), torch.empty(0), []\n",
    "    images, labels, metas = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    labels = torch.stack(labels)\n",
    "    metas = list(metas)\n",
    "    return images, labels, metas\n",
    "@torch.no_grad()\n",
    "def extract_features_dinov2(dataloader, model, device=\"cuda\"):\n",
    "    try:\n",
    "        features, labels_all, metas_all = [], [], []\n",
    "        for imgs, labels, meta_batch in tqdm(dataloader, desc=\"Extracting DINOv2 features\"):\n",
    "            if imgs.size(0) == 0:\n",
    "                continue \n",
    "            imgs = imgs.to(device)\n",
    "            feats = model(imgs).cpu()\n",
    "            features.append(feats)\n",
    "            labels_all.append(labels)\n",
    "            metas_all.extend(meta_batch)\n",
    "        features = torch.cat(features)\n",
    "        labels_all = torch.cat(labels_all)\n",
    "        return features, labels_all, metas_all\n",
    "    except Exception as e:\n",
    "        print(f\"Client can't extract the Dino features because of : {e}\")\n",
    "        # Return empty or None values explicitly to avoid implicit None\n",
    "        return torch.empty(0), torch.empty(0), []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49214e0c-64fe-4b7c-9bf7-ba943dc2b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Clustering & Visualization  === #\n",
    "def denormalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "    mean = torch.tensor(mean, dtype=tensor.dtype, device=tensor.device).view(-1,1,1)\n",
    "    std = torch.tensor(std, dtype=tensor.dtype, device=tensor.device).view(-1,1,1)\n",
    "    return tensor * std + mean\n",
    "\n",
    "# -- 3. Crop to mask/segment content (removes almost all background) --\n",
    "def crop_to_foreground(img_np, bg_val=0, margin=4):\n",
    "    # Assumes background is black (0)\n",
    "    mask = np.any(img_np != bg_val, axis=-1)\n",
    "    coords = np.argwhere(mask)\n",
    "    if coords.size == 0:\n",
    "        return img_np\n",
    "    y0, x0 = np.maximum(coords.min(axis=0) - margin, 0)\n",
    "    y1, x1 = np.minimum(coords.max(axis=0) + 1 + margin, img_np.shape[:2])\n",
    "    return img_np[y0:y1, x0:x1]\n",
    "\n",
    "# -- 4. Resize with preserved aspect ratio for neat thumbnails --\n",
    "def resize_with_aspect(img_np, max_size=(128, 128)):\n",
    "    img_pil = Image.fromarray(img_np if img_np.max() > 1 else (img_np * 255).astype('uint8'))\n",
    "    img_pil = img_pil.convert(\"RGB\")\n",
    "    img_pil.thumbnail(max_size, Image.LANCZOS)\n",
    "    return np.asarray(img_pil)\n",
    "\n",
    "# -- 5. Visualization for each cluster --\n",
    "def visualize_cluster_segments(cluster_meta_list, cluster_id, max_visualize=5):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.suptitle(f\"Cluster {cluster_id}, Size: {len(cluster_meta_list)}\", fontsize=16, y=1.08)\n",
    "    for i, meta in enumerate(cluster_meta_list[:max_visualize]):\n",
    "        img_path = meta[\"img_path\"]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_np = np.array(img)\n",
    "            img_np_cropped = crop_to_foreground(img_np)\n",
    "            img_np_display = resize_with_aspect(img_np_cropped, max_size=(128,128))\n",
    "            plt.subplot(1, max_visualize, i+1)\n",
    "            plt.imshow(img_np_display)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Cls: {meta['original_label']}\\nScore: {meta['score']:.2f}\\nImgID: {meta['original_image_index']}\\n Clip class: {meta['clip_class']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            plt.subplot(1, max_visualize, i+1)\n",
    "            plt.text(0.5, 0.5, 'Image Error', ha='center', va='center')\n",
    "            plt.axis('off')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f3a156-cf58-401c-8918-8e50cec6f36f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def draw_arrow_on_image(ax, xy_from, xy_to, color='yellow', width=2, mutation_scale=15):\n",
    "    \"\"\"Draws an arrow from xy_from to xy_to on a matplotlib axis.\"\"\"\n",
    "    ax.annotate(\n",
    "        '', xy=xy_to, xytext=xy_from,\n",
    "        arrowprops=dict(\n",
    "            arrowstyle='->',\n",
    "            color=color,\n",
    "            lw=width,\n",
    "            shrinkA=0,\n",
    "            shrinkB=0,\n",
    "            mutation_scale=mutation_scale\n",
    "        ),\n",
    "        annotation_clip=False\n",
    "    )\n",
    "\n",
    "def create_mask_overlay_from_original(original_img_path, mask_img, alpha=0.6, mask_color=(255, 180, 0)):\n",
    "    \"\"\" Overlay a binary mask onto the original full image.\"\"\"\n",
    "    orig = np.array(Image.open(original_img_path).convert(\"RGB\")).copy()\n",
    "    mask = np.array(mask_img)\n",
    "    if mask.max() > 1:\n",
    "        mask_bin = (mask[..., 0] > 0).astype(np.uint8)\n",
    "    else:\n",
    "        mask_bin = mask[..., 0]\n",
    "    mask_rgb = np.zeros_like(orig)\n",
    "    mask_rgb[mask_bin == 1] = mask_color\n",
    "    out = cv2.addWeighted(mask_rgb, alpha, orig, 1 - alpha, 0)\n",
    "    return Image.fromarray(out)\n",
    "\n",
    "def visualize_clusters_with_overlay_and_arrow(clusters_by_class, max_per_cluster=3):\n",
    "    \"\"\" Visualizes each cluster with segment (left) and overlay on original image (right), with arrow.\"\"\"\n",
    "    for class_name, cluster_info_list in clusters_by_class.items():\n",
    "        n_clusters = len(cluster_info_list)\n",
    "        fig, axes = plt.subplots(n_clusters, max_per_cluster, figsize=(5 * max_per_cluster, 4 * n_clusters))\n",
    "        if n_clusters == 1:\n",
    "            axes = np.expand_dims(axes, 0)\n",
    "        plt.suptitle(f\"Class: {class_name} Clusters (sorted by CLIP saliency)\", fontsize=16)\n",
    "\n",
    "        for r, (cluster, info) in enumerate(cluster_info_list):\n",
    "            for c in range(max_per_cluster):\n",
    "                ax = axes[r, c] if n_clusters > 1 else axes[0, c]\n",
    "                try:\n",
    "                    meta = cluster[c]\n",
    "                except IndexError:\n",
    "                    ax.axis('off')\n",
    "                    continue\n",
    "\n",
    "                # Load the segment image as saved (RGB)\n",
    "                seg_img = Image.open(meta['img_path']).convert(\"RGB\")\n",
    "                seg_np = np.array(seg_img)\n",
    "\n",
    "                # Derive binary mask (used only for overlay)\n",
    "                gray = cv2.cvtColor(seg_np, cv2.COLOR_RGB2GRAY)\n",
    "                mask_only = np.where(gray > 5, 255, 0).astype(np.uint8)\n",
    "                mask_only = np.expand_dims(mask_only, axis=-1)\n",
    "\n",
    "                # Load the original image and create overlay\n",
    "                orig_img_path = meta['original_image_path']\n",
    "                overlay_img = create_mask_overlay_from_original(orig_img_path, mask_only, alpha=0.6)\n",
    "\n",
    "                # Resize both views\n",
    "                thumb_segment = seg_img.resize((64, 64), Image.LANCZOS)\n",
    "                thumb_overlay = overlay_img.resize((128, 128), Image.LANCZOS)\n",
    "\n",
    "                # Compose side-by-side image\n",
    "                combined = Image.new('RGB', (thumb_segment.width + thumb_overlay.width, thumb_overlay.height), (255, 255, 255))\n",
    "                combined.paste(thumb_segment, (0, 0))\n",
    "                combined.paste(thumb_overlay, (thumb_segment.width, 0))\n",
    "\n",
    "                # Show in subplot\n",
    "                ax.imshow(combined)\n",
    "                ax.axis('off')\n",
    "\n",
    "                # Draw arrow between segment and overlay\n",
    "                arrow_start = (thumb_segment.width // 2, thumb_overlay.height // 2)\n",
    "                arrow_end = (thumb_segment.width + thumb_overlay.width // 2, thumb_overlay.height // 2)\n",
    "                draw_arrow_on_image(ax, arrow_start, arrow_end)\n",
    "\n",
    "                # Add title with cluster info\n",
    "                ax.set_title(f\"CID: {info['cluster_id']} | Score: {meta['clip_score']:.2f} \\n Clip Interpretation:{meta['clip_class']}\", fontsize=9)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "        plt.show()\n",
    "\n",
    "class InceptionContext:\n",
    "    def __init__(self, device):\n",
    "        self.inception_model = inception_v3(weights='IMAGENET1K_V1').to(device)\n",
    "        self.inception_model.eval()\n",
    "        self.inception_features = {}\n",
    "        self.gradients = {}\n",
    "        self.inception_preproc = transforms.Compose([\n",
    "            transforms.Resize((299, 299)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.device = device\n",
    "\n",
    "        # Register hooks, binding self as closure via lambda or inner function\n",
    "        def hook_fn(module, input, output):\n",
    "            self.inception_features['mixed_8'] = output.detach()\n",
    "\n",
    "        def save_gradient(module, grad_input, grad_output):\n",
    "            self.gradients['mixed_8'] = grad_output[0]\n",
    "\n",
    "        self.inception_model.Mixed_7b.register_forward_hook(hook_fn)\n",
    "        self.inception_model.Mixed_7b.register_backward_hook(save_gradient)\n",
    "def extract_mixed8_features(segment_metas, context):\n",
    "    images = []\n",
    "    feats = []\n",
    "    for meta in segment_metas:\n",
    "        img_path = meta['img_path']\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = context.inception_preproc(img)\n",
    "        images.append(img_tensor)\n",
    "    if not images:\n",
    "        return np.zeros((0, 1280))\n",
    "    batch_size = 512\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch=torch.stack(images[i:i + batch_size]).to(context.device)\n",
    "        with torch.no_grad():\n",
    "            _ = context.inception_model(batch)\n",
    "            batch_feats = context.inception_features['mixed_8'].mean(dim=[2, 3])\n",
    "        feats.append(batch_feats.cpu().numpy())    \n",
    "        torch.cuda.empty_cache()\n",
    "    return np.concatenate(feats, axis=0)\n",
    "\n",
    "def get_mixed8_gradients_G(img, target_class_idx, context):\n",
    "    context.inception_features.clear()\n",
    "    context.gradients.clear()\n",
    "    tensor = context.inception_preproc(img).unsqueeze(0).to(context.device)\n",
    "    tensor.requires_grad_(True)\n",
    "    output = context.inception_model(tensor)\n",
    "    target_logit = output[:, target_class_idx]\n",
    "    context.inception_model.zero_grad()\n",
    "    target_logit.backward()\n",
    "    grad = context.gradients['mixed_8'].detach().cpu().numpy().squeeze()\n",
    "    grad_pooled = grad.mean(axis=(1,2))\n",
    "    return grad_pooled\n",
    "\n",
    "def compute_tcav_score_for_class_G(class_images, cav, target_class_idx, context):\n",
    "    pos = 0\n",
    "    for img in class_images:\n",
    "        grad_pooled = get_mixed8_gradients_G(img, target_class_idx, context)\n",
    "        grad_pooled = grad_pooled / np.linalg.norm(grad_pooled)\n",
    "        if np.dot(grad_pooled, cav) > 0:\n",
    "            pos += 1\n",
    "    return pos / len(class_images)\n",
    "    \n",
    "#def hook_fn(module, input, output):\n",
    "#        inception_features['mixed_8'] = output.detach()\n",
    "\n",
    "#def save_gradient(module, grad_input, grad_output):\n",
    "#        gradients['mixed_8'] = grad_output[0]\n",
    "\n",
    "#        inception_model.Mixed_7b.register_forward_hook(hook_fn)\n",
    "#        inception_model.Mixed_7b.register_backward_hook(save_gradient)\n",
    "\n",
    "#        inception_preproc = transforms.Compose([\n",
    "#            transforms.Resize((299, 299)),\n",
    "#            transforms.ToTensor(),\n",
    "#            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#        ])\n",
    "\n",
    "#def extract_mixed8_features(segment_metas):\n",
    "#            images = []\n",
    "#            feats = []\n",
    "#            for meta in segment_metas:\n",
    "#                img_path = meta['img_path']\n",
    "#                img = Image.open(img_path).convert('RGB')\n",
    "#                img_tensor = inception_preproc(img)\n",
    "#                images.append(img_tensor)\n",
    "#            if not images:\n",
    "#                return np.zeros((0, 1280))\n",
    "#            batch_size = 512\n",
    "#            for i in range(0, len(images), batch_size):\n",
    "#                batch=torch.stack(images[i:i + batch_size]).to(self.device)\n",
    "#                with torch.no_grad():\n",
    "#                    _ = inception_model(batch)\n",
    "#                    batch_feats = inception_features['mixed_8'].mean(dim=[2, 3])\n",
    "#                feats.append(batch_feats.cpu().numpy())    \n",
    "#                torch.cuda.empty_cache()\n",
    "#            return np.concatenate(feats, axis=0)\n",
    "\n",
    "def calculate_cav(concept_features, random_features):\n",
    "            X = np.concatenate([concept_features, random_features], axis=0)\n",
    "            y = np.array([1]*len(concept_features) + [0]*len(random_features))\n",
    "            clf = LogisticRegression(max_iter=1000)\n",
    "            clf.fit(X, y)\n",
    "            cav = clf.coef_[0]\n",
    "            cav = cav / np.linalg.norm(cav)\n",
    "            mean_pos = np.mean(np.dot(concept_features, cav))\n",
    "            mean_neg = np.mean(np.dot(random_features, cav))\n",
    "            if mean_pos < mean_neg:\n",
    "                cav = -cav\n",
    "            return cav \n",
    "\n",
    "#def get_mixed8_gradients_G(img, target_class_idx):\n",
    "#            inception_features.clear()\n",
    "#            gradients.clear()\n",
    "#            tensor = inception_preproc(img).unsqueeze(0).to(self.device)\n",
    "#            tensor.requires_grad_(True)\n",
    "#            output = inception_model(tensor)\n",
    "#            target_logit = output[:, target_class_idx]\n",
    "#            inception_model.zero_grad()\n",
    "#            target_logit.backward()\n",
    "#            grad = gradients['mixed_8'].detach().cpu().numpy().squeeze()\n",
    "#            grad_pooled = grad.mean(axis=(1,2))\n",
    "#            return grad_pooled\n",
    "\n",
    "#def compute_tcav_score_for_class_G(class_images, cav, target_class_idx):\n",
    "#            pos = 0\n",
    "#            for img in class_images:\n",
    "#                grad_pooled = get_mixed8_gradients_G(img, target_class_idx)\n",
    "#                grad_pooled = grad_pooled / np.linalg.norm(grad_pooled)\n",
    "#                if np.dot(grad_pooled, cav) > 0:\n",
    "#                    pos += 1\n",
    "#            return pos / len(class_images)\n",
    "\n",
    "def load_test_images_by_class_G(test_dir):\n",
    "            class_images = {}\n",
    "            for class_label in os.listdir(test_dir):\n",
    "                if class_label.startswith('.'):\n",
    "                    continue\n",
    "                class_path = os.path.join(test_dir, class_label)\n",
    "                if not os.path.isdir(class_path):\n",
    "                    continue\n",
    "                imgs = []\n",
    "                for fname in os.listdir(class_path):\n",
    "                    if fname.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                        img = Image.open(os.path.join(class_path, fname)).convert('RGB')\n",
    "                        imgs.append(img)\n",
    "                class_images[class_label] = imgs\n",
    "            return class_images\n",
    "\n",
    "def plot_tcav_heatmap(tcav_matrix, class_labels, cluster_labels, client_id, out_dir=\"cluster_visualizations\", concept_class=\"???\"):\n",
    "            \"\"\"\n",
    "            tcav_matrix: np.ndarray of shape (num_clusters, num_classes)\n",
    "            class_labels: list of class names (columns)\n",
    "            cluster_labels: list of cluster names/ids (rows)\n",
    "            client_id: client numeric id\n",
    "            out_dir: directory to save the output image\n",
    "            \"\"\"\n",
    "            import matplotlib\n",
    "            import matplotlib.pyplot as plt\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            fig, ax = plt.subplots(figsize=(1.2 * len(class_labels) + 2, 0.8 * len(cluster_labels) + 3))\n",
    "            cmap = matplotlib.colors.LinearSegmentedColormap.from_list('red_green', ['red', 'yellow', 'green'])\n",
    "            cax = ax.imshow(tcav_matrix, cmap=cmap, vmin=0., vmax=1.)\n",
    "\n",
    "            for i in range(tcav_matrix.shape[0]):\n",
    "                for j in range(tcav_matrix.shape[1]):\n",
    "                    val = tcav_matrix[i, j]\n",
    "                    ax.text(j, i, f\"{val:.2f}\", va='center', ha='center',\n",
    "                            color=\"black\" if val < 0.5 else \"white\", fontsize=10, fontweight='bold')\n",
    "            ax.set_xticks(np.arange(len(class_labels)))\n",
    "            ax.set_yticks(np.arange(len(cluster_labels)))\n",
    "            ax.set_xticklabels(class_labels, rotation=45, ha=\"right\", fontsize=12)\n",
    "            ax.set_yticklabels(cluster_labels, fontsize=12)\n",
    "            ax.set_xlabel(\"Class label\")\n",
    "            ax.set_ylabel(\"Concept (Cluster)\")\n",
    "            plt.title(f\"TCAV class {concept_class} Concepts Contribution\\nClient {client_id}\", fontsize=15, pad=25)\n",
    "            plt.colorbar(cax, ax=ax, fraction=0.045)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(out_dir, f\"TCAV_heatmap_class_{concept_class}_client{client_id}.png\"))\n",
    "            plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ed945-a40d-4a87-9605-1b532c62df68",
   "metadata": {},
   "source": [
    "### Federated server strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd192bf8-1439-4210-a151-f835e20f785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedKMeansStrategy(Strategy):\n",
    "    def __init__(self, initial_centroids, num_clusters=10, tol=1e-3):\n",
    "        self.global_centroids = initial_centroids\n",
    "        self.num_clusters = num_clusters\n",
    "        self.tol = tol\n",
    "        self.converged = False\n",
    "        self.silhouette_history = defaultdict(lambda: defaultdict(list))\n",
    "        self.global_tcav_clients = set()\n",
    "        self.finished = False\n",
    "        self.global_cavs = None  \n",
    "        self.label_to_classname = {'basketball': 0, 'mountain bike': 1, 'moving van': 2}\n",
    "\n",
    "    def initialize_parameters(self, client_manager):\n",
    "        return ndarrays_to_parameters([])\n",
    "\n",
    "    def configure_fit(self, server_round, parameters, client_manager):\n",
    "        config = {}\n",
    "        if getattr(self, \"finished\", False):\n",
    "            print(\"[Server] Simulation finished after global TCAV. No more rounds.\")\n",
    "            return []\n",
    "        print(f\"[Strategy] configure_fit called for round {server_round}\")\n",
    "        print(f\"[Strategy] Available clients: {len(client_manager.all())}\")\n",
    "        if len(client_manager.all()) == 0:\n",
    "            return []\n",
    "\n",
    "        if self.converged:\n",
    "        # Pass flags to indicate what client should do\n",
    "            #print (f\" this is the global_CAV {self.global_cavs}\")\n",
    "            if self.global_cavs:\n",
    "                print(\"[Server] Sending GLOBAL TCAV configs.\")\n",
    "                config[\"mode\"] = \"tcav\"\n",
    "                config[\"do_global_tcav\"] = True  # Tell clients to run global TCAV\n",
    "                config[\"global_cavs\"] = json.dumps(self.global_cavs)\n",
    "            else:\n",
    "                print(\"[Server] Sending LOCAL TCAV configs.\")\n",
    "                config[\"mode\"] = \"tcav\"\n",
    "                config[\"do_global_tcav\"] = False  # Only run local TCAV\n",
    "        else:\n",
    "            print(\"[Server] Still in Clustering mode \")\n",
    "            config[\"mode\"] = \"cluster\"\n",
    "        \n",
    "        #if not self.converged:\n",
    "        serialized = {int(k): v.tolist() for k, v in self.global_centroids.items()}\n",
    "        config[\"centroids\"] = json.dumps(serialized) \n",
    "\n",
    "        dummy = ndarrays_to_parameters([np.zeros((1, 1), dtype=np.float32)])\n",
    "        fit_ins = FitIns(parameters=dummy, config=config)\n",
    "        return [(client, fit_ins) for client in client_manager.all().values()]\n",
    "\n",
    "    def aggregate_fit(self, server_round, results, failures):\n",
    "\n",
    "        if failures:\n",
    "            print(f\"[Server] {len(failures)} client failures in round {server_round}:\")\n",
    "            for failure in failures:\n",
    "                print(f\"  - Failure: {str(failure)}\")\n",
    "\n",
    "        if self.converged :\n",
    "            dummy = ndarrays_to_parameters([np.zeros((1, 1), dtype=np.float32)])\n",
    "            cavs_per_concept = defaultdict(list)  # (class_label, cluster_id) -> list of (cav, count)\n",
    "            for client_proxy, fit_res in results:\n",
    "                cav_results = fit_res.metrics.get(\"cav_results\")\n",
    "                if cav_results is not None:\n",
    "                    cav_results = json.loads(cav_results)\n",
    "                    for key, value in cav_results.items():\n",
    "                        class_name, cluster_id = key.rsplit('_', 1)\n",
    "                        cluster_id = int(cluster_id)\n",
    "                        class_label = self.label_to_classname[class_name]\n",
    "                        cav = np.array(value['cav'])\n",
    "                        count = value['count']\n",
    "                        cavs_per_concept[(class_label, cluster_id)].append((cav, count))\n",
    "            global_cavs = {}\n",
    "            for (class_label, cluster_id), cav_list in cavs_per_concept.items():\n",
    "                total_count = sum(cnt for _, cnt in cav_list)\n",
    "                if total_count == 0:\n",
    "                    continue\n",
    "                weighted_cav = sum(cav * cnt for cav, cnt in cav_list) / total_count\n",
    "                weighted_cav = weighted_cav / np.linalg.norm(weighted_cav)\n",
    "                global_cavs[f\"{class_label}_{cluster_id}\"] = weighted_cav.tolist()\n",
    "            if global_cavs:  # Only set if we got CAVs!\n",
    "                self.global_cavs = global_cavs\n",
    "                print(f\"[Server] Aggregated and set {len(global_cavs)} global CAVs for global TCAV phase.\")\n",
    "            for client_proxy, fit_res in results:\n",
    "                    metrics = fit_res.metrics\n",
    "                    if metrics.get(\"global_tcav_ran\"):\n",
    "                        self.global_tcav_clients.add(getattr(client_proxy, 'cid', str(client_proxy)))\n",
    "            if len(self.global_tcav_clients) == len(results):  # or num_clients if more robust\n",
    "                print(\"[Server] All clients finished global TCAV. Ending simulation.\")\n",
    "                self.finished = True\n",
    "            return dummy, {}\n",
    "\n",
    "        all_cluster_data = []\n",
    "        per_class_clusters = defaultdict(list)  # class_label -> list of (centroid, count)\n",
    "        for client_proxy, fit_res in results:\n",
    "            #cluster_data_json = fit_res.metrics.get(\"cluster_data\")\n",
    "            client_id = getattr(client_proxy, 'cid', str(client_proxy))\n",
    "            avg_silhouette_scores = fit_res.metrics.get('avg_silhouette_scores')\n",
    "            if avg_silhouette_scores is not None:\n",
    "                avg_silhouette_scores = json.loads(avg_silhouette_scores)\n",
    "            for class_label, avg_sil in avg_silhouette_scores.items():\n",
    "                self.silhouette_history[client_id][int(class_label)].append(avg_sil)\n",
    "            arrays = parameters_to_ndarrays(fit_res.parameters)\n",
    "            #if cluster_data_json is None:\n",
    "            #    continue\n",
    "            if len(arrays) != 4:\n",
    "                print(\"Malformed client parameters\")\n",
    "                continue\n",
    "            centroids, counts, class_labels, cluster_indices = arrays\n",
    "            #cluster_data_dict = json.loads(cluster_data_json)\n",
    "            for centroid, count, class_label, cl_idx in zip(centroids, counts, class_labels, cluster_indices):\n",
    "                        per_class_clusters[int(class_label)].append((centroid, count, int(cl_idx)))\n",
    "\n",
    "        new_global_centroids = {}\n",
    "        for class_label, centroid_list in per_class_clusters.items():\n",
    "            if not centroid_list:\n",
    "                continue\n",
    "            n_clusters = len(centroid_list)\n",
    "            # Organize by cluster index if it is present in entry, else assign sequentially\n",
    "            sum_centroids = None\n",
    "            total_counts = None\n",
    "            K = self.num_clusters if hasattr(self, \"num_clusters\") else n_clusters\n",
    "            sum_centroids = np.zeros((K, centroid_list[0][0].shape[0]), dtype=np.float32)\n",
    "            total_counts = np.zeros(K, dtype=np.float32)\n",
    "            for i, (centroid, count,cluster_index) in enumerate(centroid_list):\n",
    "                idx = i % K\n",
    "                sum_centroids[idx] += centroid * count\n",
    "                total_counts[idx] += count\n",
    "            for idx in range(K):\n",
    "                if total_counts[idx] > 0:\n",
    "                    sum_centroids[idx] /= total_counts[idx]\n",
    "            new_global_centroids[class_label] = sum_centroids\n",
    "\n",
    "        max_shift = 0.0\n",
    "        for class_label in new_global_centroids:\n",
    "            if class_label in self.global_centroids:\n",
    "                shift = np.linalg.norm(self.global_centroids[class_label] - new_global_centroids[class_label], axis=1)\n",
    "                max_shift = max(max_shift, np.max(shift))\n",
    "        self.global_centroids = new_global_centroids\n",
    "        #shift = np.linalg.norm(self.global_centroids - new_centroids, axis=1)\n",
    "        #max_shift = np.max(shift)\n",
    "        print(f\"[Round {server_round}] Max centroid shift: {max_shift:.2f}\")\n",
    "        if max_shift < self.tol:\n",
    "            print(\"Convergence achieved. Switching to TCAV phase.\")\n",
    "            self.converged = True\n",
    "            for client_id in self.silhouette_history:\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                for class_label in self.silhouette_history[client_id]:\n",
    "                    plt.plot(self.silhouette_history[client_id][class_label],label=f\"Class {class_label}\")\n",
    "                plt.xlabel(\"Round\")\n",
    "                plt.ylabel(\"Average Silhouette Score\")\n",
    "                plt.title(f\"Client {client_id}: Avg. Silhouette Score per Class (Clustering Rounds)\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"cluster_visualizations/silhouette_history_client{client_id}.png\")\n",
    "                plt.close()\n",
    "        dummy = ndarrays_to_parameters([np.zeros((1, 1), dtype=np.float32)])\n",
    "        return dummy, {}\n",
    "\n",
    "    def evaluate(self, server_round, parameters):\n",
    "        print(f\"[Server] Global evaluation for round {server_round} skipped (no global model).\")\n",
    "        return 0.0, {}\n",
    "\n",
    "    def configure_evaluate(self, server_round, parameters, client_manager):\n",
    "        mode = \"tcav\" if self.converged else \"cluster\"\n",
    "        config = {\"mode\": mode}\n",
    "        serialized = {int(k): v.tolist() for k, v in self.global_centroids.items()}  # Serialize to JSON string\n",
    "        config = {\n",
    "        \"mode\": mode,\n",
    "        \"centroids\": json.dumps(serialized)\n",
    "    }\n",
    "        dummy = ndarrays_to_parameters([np.zeros((1, 1), dtype=np.float32)])\n",
    "        evaluate_ins = EvaluateIns(parameters=dummy, config=config)\n",
    "        return [(client, evaluate_ins) for client in client_manager.all().values()]\n",
    "\n",
    "    def aggregate_evaluate(self, server_round, results, failures):\n",
    "        return 0.0, {}\n",
    "        if not results:\n",
    "            return 0.0, {}\n",
    "\n",
    "        total_samples = 0\n",
    "        total_inertia = 0.0\n",
    "        all_cluster_sizes = defaultdict(lambda: defaultdict(int))  # class_label -> cluster_idx -> count\n",
    "\n",
    "        for client, client_res in results:\n",
    "            metrics = client_res.metrics\n",
    "            num_samples = client_res.num_examples\n",
    "            # Inertia is per class (sum over clusters within class)\n",
    "            if \"inertia\" in metrics:\n",
    "                class_inertia = json.loads(metrics[\"inertia\"])\n",
    "                for class_label, inertia in class_inertia.items():\n",
    "                    total_inertia += float(inertia)\n",
    "                    total_samples += num_samples  # You can sum per sample or per class\n",
    "\n",
    "            if \"cluster_sizes\" in metrics:\n",
    "                cluster_sizes = json.loads(metrics[\"cluster_sizes\"])\n",
    "                for class_label, clusters in cluster_sizes.items():\n",
    "                    for cluster_idx, sz in clusters.items():\n",
    "                        all_cluster_sizes[int(class_label)][int(cluster_idx)] += sz\n",
    "\n",
    "        avg_inertia = total_inertia / total_samples if total_samples else 0.0\n",
    "        print(f\"\\n[Server][Evaluation Round {server_round}]\")\n",
    "        print(f\"  > Avg Inertia: {avg_inertia:.2f}\")\n",
    "        for class_label, c_sizes in all_cluster_sizes.items():\n",
    "            print(f\"  > Class {class_label} cluster sizes: {dict(c_sizes)}\")\n",
    "        metrics = {\n",
    "            \"avg_inertia\": avg_inertia,\n",
    "            \"global_cluster_sizes\": {cl: dict(c_sizes) for cl, c_sizes in all_cluster_sizes.items()}\n",
    "        }\n",
    "        return total_samples, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc36e76-d9b5-4a67-b1bb-53a621ba0028",
   "metadata": {},
   "source": [
    "### Federated Client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6f33b95-02a7-44a6-a7b4-f8d12dbde01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThesisKMeansClient(NumPyClient):\n",
    "    def __init__(self, cid, features, labels, metas, device):\n",
    "        print(f\"[Client] {cid} Initializing with features: {type(features)}, shape: {getattr(features, 'shape', 'no shape')}\")\n",
    "        print(f\"[Client] {cid} Labels: {type(labels)}, length: {len(labels) if hasattr(labels, '__len__') else 'no length'}\")\n",
    "        print(f\"[Client] {cid} Metas: {type(metas)}, length: {len(metas) if hasattr(metas, '__len__') else 'no length'}\")\n",
    "    \n",
    "        # Validate data\n",
    "        if hasattr(features, 'shape') and features.shape[0] == 0:\n",
    "            raise ValueError(\"Features array is empty\")\n",
    "        if len(labels) == 0:\n",
    "            raise ValueError(\"Labels list is empty\")\n",
    "        if len(metas) == 0:\n",
    "            raise ValueError(\"Metas list is empty\")\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.metas = metas\n",
    "        self.k = 15\n",
    "        self.cluster_labels = None\n",
    "        self.cluster_cache = None\n",
    "        self.dinov2 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').to(device).eval()\n",
    "        self.device = device\n",
    "        self.current_centroid = None\n",
    "        self.cid = cid\n",
    "        self.label_to_classname = { 0:'basketball', 1: 'mountain bike', 2: 'moving van'}\n",
    "        class_feature_map = defaultdict(list)\n",
    "        class_meta_map = defaultdict(list)\n",
    "        self.tcav_ran =False\n",
    "        self.global_cav_received = False\n",
    "    def get_parameters(self, config):\n",
    "        return []\n",
    "\n",
    "            \n",
    "    def fit(self, parameters, config) -> tuple[list[np.ndarray], int, dict[str, float | int | str | bytes | bool]]:\n",
    "        from export_global_tcav_to_lrxfl_once import export_global_tcav_binary_once\n",
    "        try:\n",
    "            from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "            print(\"📦 fit() called on client.\")\n",
    "            mode = config[\"mode\"]\n",
    "            \n",
    "            if mode == \"tcav\":\n",
    "                do_global_tcav = config.get(\"do_global_tcav\", False)\n",
    "                metrics = {}\n",
    "                if do_global_tcav :\n",
    "        #=======================>>>>>>>>>>>>>>>>  Calculating the Global Concepts<<<<<<<<<<<<===========================\n",
    "                    #inception_features = {}\n",
    "                    #gradients = {}\n",
    "                    context = InceptionContext(self.device)\n",
    "                    global_cavs = json.loads(config[\"global_cavs\"])\n",
    "                    test_dir = '/gpfs/helios/home/mahmouds/Thesis/Test'\n",
    "                    class_to_inception_idx = {\n",
    "                        'basketball': 816,\n",
    "                        'mountain bike': 162,\n",
    "                        'moving van': 191\n",
    "                            }\n",
    "                    test_images = load_test_images_by_class_G(test_dir) \n",
    "                    # =======================================================>>>>>>>>>>>>>>>>>>>>>>>>>>> LR-XFL <<<<<<<<<<<<<<<<<<<<<<<<<<<<<==================================\n",
    "                    label_to_name = {int(cid): cname for cid, cname in self.label_to_classname.items()}\n",
    "                    name_to_id = {v: k for k, v in self.label_to_classname.items()}\n",
    "                    def _image_iter_G():\n",
    "                        for class_name, imgs in test_images.items():\n",
    "                            if class_name not in name_to_id:\n",
    "                                continue\n",
    "                            y = name_to_id[class_name]\n",
    "                            for im in imgs:\n",
    "                                 yield im, y\n",
    "                    _get_grad_G = lambda img, idx: get_mixed8_gradients_G(img, idx, context)\n",
    "                    export_global_tcav_binary_once(\n",
    "                                                    shared_dir=\"./data/IMAGENET_LRXFL_SHARED\",     # <- change if you want another output dir\n",
    "                                                    label_to_name=label_to_name,                    # {class_id -> class_name}\n",
    "                                                    clusters_per_class=self.k,                      # uniform K you already use\n",
    "                                                    global_cavs=global_cavs,                        # {\"cid_kid\": list} from the server\n",
    "                                                    class_to_inception_idx_namekey=class_to_inception_idx,  # {class_name -> inception_idx}\n",
    "                                                    get_grad_vec_G=_get_grad_G,                     # global gradient fn\n",
    "                                                    image_iter_G=_image_iter_G(),                   # shared test images\n",
    "                                                    overwrite=False,  \n",
    "                                                    threshold=0.6, # keep False so only the first writer writes\n",
    "                                                    )\n",
    "                    # =======================================================>>>>>>>>>>>>>>>>>>>>>>>>>>> End of LR-XFL <<<<<<<<<<<<<<<<<<<<<<<<<<<<<==================================\n",
    "                    Gclusters = list(global_cavs.keys())\n",
    "                    print (f\"listing the Global_cav keys {Gclusters}\")\n",
    "                    Gparsed_clusters = [tuple(map(int, key.split('_'))) for key in Gclusters]\n",
    "                    print (f\"listing the Gparsed_clusters {Gparsed_clusters}\")\n",
    "                    Gcluster_labels = [f\"{self.label_to_classname.get(cl, cl)}-C{cid}\" for cl, cid in Gparsed_clusters]\n",
    "                    print(f\"Gcluster_labels {Gcluster_labels}\")\n",
    "                    Gclass_labels = sorted(test_images.keys())\n",
    "                    print(f\"Gclass_labels {Gclass_labels}\")\n",
    "                    #unique_classes = sorted(set(cl for cl, _ in Gclusters))\n",
    "                    tcav_matrix = np.zeros((len(Gclusters), len(Gclass_labels)))\n",
    "                    for i, (class_label_int, cid) in enumerate(Gparsed_clusters):\n",
    "                        class_name = self.label_to_classname[class_label_int] \n",
    "                        cav = np.array(global_cavs[f\"{class_label_int}_{cid}\"])\n",
    "                        for j, test_class in enumerate(Gclass_labels):\n",
    "                            if test_class not in test_images or class_name not in class_to_inception_idx:\n",
    "                                tcav_matrix[i, j] = np.nan\n",
    "                                continue\n",
    "                            score = compute_tcav_score_for_class_G(test_images[test_class], cav, class_to_inception_idx[test_class], context)\n",
    "                            tcav_matrix[i, j] = score\n",
    "                    print (f\"Global TCAV Matrix:{tcav_matrix}\")\n",
    "                    out_dir = \"cluster_visualizations\"\n",
    "                    for concept_class in set(cl for cl, _ in Gparsed_clusters):\n",
    "                        rows = [i for i, (cl, _) in enumerate(Gparsed_clusters) if cl == concept_class]\n",
    "                        if not rows:\n",
    "                            continue\n",
    "                        submatrix = tcav_matrix[rows, :]\n",
    "                        sub_cluster_labels = [Gcluster_labels[i] for i in rows]\n",
    "                        # Save heatmap, label it as \"Global\"\n",
    "                        plot_tcav_heatmap(submatrix, Gclass_labels, sub_cluster_labels, client_id=self.cid, out_dir=out_dir, concept_class=f\"{self.label_to_classname.get(concept_class, concept_class)} (Global)\")\n",
    "                        print(f\"[Client {self.cid}] Saved **Global** TCAV class{concept_class} concepts heatmap to {out_dir}/TCAV_heatmap_class_{concept_class}_client{self.cid}_global.png\")\n",
    "\n",
    "                    metrics = {\"global_tcav_ran\": True}\n",
    "                    dummy_array = np.zeros((self.k, self.features.shape[1]), dtype=np.float32)\n",
    "                    return [dummy_array], 0, metrics\n",
    "            #=======================>>>>>>>>>>>>>>>> End of  Calculating the Global Concepts<<<<<<<<<<<<===========================\n",
    "                \n",
    "                metrics[\"tcav_ran\"] = True\n",
    "                class_feature_map = defaultdict(list)\n",
    "                class_meta_map = defaultdict(list)\n",
    "                centroids_dict = json.loads(config[\"centroids\"])\n",
    "                centroids_dict = {int(k): np.array(v, dtype=np.float32) for k, v in centroids_dict.items()}\n",
    "                print(f\" [CLient {self.cid}] is Converged and start constructing the needed Clusters\")\n",
    "            \n",
    "                for f, m in zip(self.features, self.metas):\n",
    "                    class_label = m['original_label']\n",
    "                    class_feature_map[class_label].append(f)\n",
    "                    class_meta_map[class_label].append(m)\n",
    "                #print(f\"Discovered {len(self.class_feature_map)} unique classes\")\n",
    "                for class_label in class_feature_map:\n",
    "                    if class_label not in centroids_dict:\n",
    "                        print(f\"Skipping class {class_label}: no converged centroids from server.\")\n",
    "                        continue\n",
    "                    features_class = np.stack(class_feature_map[class_label])\n",
    "                    metas_class =class_meta_map[class_label]\n",
    "                    centroids = centroids_dict[class_label]\n",
    "                    # Assign each feature to closest cluster in final centroids\n",
    "                    assigned_labels = pairwise_distances_argmin(features_class, centroids)\n",
    "                    for meta, cid in zip(metas_class, assigned_labels):\n",
    "                        meta['cluster_id'] = int(cid)\n",
    "                #self.save_state()\n",
    "                print(f\" [CLient {self.cid}] is Proceeding for Training CAVs and computing TCAV scores...\")\n",
    "                print(f\" [CLient {self.cid}] Picking up the nearest 40 instaces to the clusters' centriods...\")\n",
    "                # === Keep only closest 40 points per cluster and update features/labels/metas =======================================\n",
    "                filtered_metas_global = []                                                                                           #\n",
    "                filtered_indices_global = []                                                                                         #\n",
    "                for class_label in class_feature_map:                                                                                #\n",
    "                    if class_label not in centroids_dict:                                                                            #\n",
    "                        continue                                                                                                     #\n",
    "                    features_class = np.stack(class_feature_map[class_label])                                                        #\n",
    "                    metas_class = class_meta_map[class_label]                                                                        #\n",
    "                    centroids = centroids_dict[class_label]                                                                          #\n",
    "                    assigned_labels = pairwise_distances_argmin(features_class, centroids)                                           #\n",
    "                    for cid in range(centroids.shape[0]):                                                                            #\n",
    "                        idxs = np.where(assigned_labels == cid)[0]                                                                   #\n",
    "                        if len(idxs) == 0:                                                                                           #\n",
    "                            continue                                                                                                 #\n",
    "                        cluster_feats = features_class[idxs]                                                                         #\n",
    "                        dists = np.linalg.norm(cluster_feats - centroids[cid], axis=1)                                               #\n",
    "                        sort_idxs = np.argsort(dists)[:40]                                                                           #\n",
    "                        selected_metas = [metas_class[idxs[i]] for i in sort_idxs]                                                   #\n",
    "                        selected_indices = [idxs[i] for i in sort_idxs]                                                              #\n",
    "                        filtered_metas_global.extend(selected_metas)                                                                 #\n",
    "                        filtered_indices_global.extend([ (class_label, idx) for idx in selected_indices ])                           #\n",
    "                # Rebuild features, labels, metas: (preserving exact order)                                                          #\n",
    "                all_features = []                                                                                                    #\n",
    "                all_labels = []                                                                                                      #\n",
    "                all_metas = []                                                                                                       #\n",
    "                class_to_indices = { cl: np.array([i for i in range(len(class_feature_map[cl]))]) for cl in class_feature_map }      #\n",
    "                for (class_label, idx) in filtered_indices_global:                                                                   #\n",
    "                    all_features.append(class_feature_map[class_label][idx])                                                         #\n",
    "                    all_labels.append(class_label)                                                                                   #\n",
    "                    all_metas.append(class_meta_map[class_label][idx])                                                               #\n",
    "                self.features = np.stack(all_features)                                                                               #\n",
    "                self.labels = np.array(all_labels)                                                                                   #\n",
    "                self.metas = all_metas                                                                                               #\n",
    "                cav_results=self.train_cavs_and_tcav()\n",
    "                metrics[\"cav_results\"] = json.dumps(cav_results)\n",
    "                dummy_array = np.zeros((self.k, self.features.shape[1]), dtype=np.float32)\n",
    "                return [dummy_array], 0, metrics  # Return NDArrays (list of np.ndarray), int, dict\n",
    "            \n",
    "            if \"centroids\" not in config:\n",
    "                raise ValueError(\"Missing 'centroids' in config\")\n",
    "            avg_silhouette_scores = {}\n",
    "            centroids_dict = json.loads(config[\"centroids\"])\n",
    "            centroids_dict = {int(k): np.array(v, dtype=np.float32) for k, v in centroids_dict.items()}\n",
    "            class_feature_map = defaultdict(list)\n",
    "            class_meta_map = defaultdict(list)\n",
    "            for f, m in zip(self.features, self.metas):\n",
    "                class_label = m['original_label']\n",
    "                class_feature_map[class_label].append(f)\n",
    "                class_meta_map[class_label].append(m)\n",
    "            print(f\"Discovered {len(class_feature_map)} unique classes\")\n",
    "            per_class_cluster_data = {}\n",
    "            for class_label in class_feature_map:\n",
    "                if class_label not in centroids_dict:\n",
    "                    print(f\"[Client {self.cid}]: Skipping class {class_label} (no centroids from server)\")\n",
    "                    continue\n",
    "                #print(f\"== [Client {self.cid}] CUDA: allocated {torch.cuda.memory_allocated() // (1024*1024)} MB, reserved {torch.cuda.memory_reserved() // (1024*1024)} MB\")\n",
    "                features_class = np.stack(class_feature_map[class_label])\n",
    "                #print(f\"== [Client {self.cid}] CUDA: allocated {torch.cuda.memory_allocated() // (1024*1024)} MB, reserved {torch.cuda.memory_reserved() // (1024*1024)} MB\")\n",
    "                metas_class = class_meta_map[class_label]\n",
    "                #print(f\"== [Client {self.cid}] CUDA: allocated {torch.cuda.memory_allocated() // (1024*1024)} MB, reserved {torch.cuda.memory_reserved() // (1024*1024)} MB\")\n",
    "                k = centroids_dict[class_label].shape[0]\n",
    "                centroids = centroids_dict[class_label]\n",
    "                print(f\"\\n[Client {self.cid}]  Class {class_label}: {features_class.shape[0]} segments\")\n",
    "                #print(f\"== [Client {self.cid}] CUDA: allocated {torch.cuda.memory_allocated() // (1024*1024)} MB, reserved {torch.cuda.memory_reserved() // (1024*1024)} MB\")\n",
    "                if features_class.shape[0] < k:\n",
    "                    print(f\"[Client {self.cid}] Skipping class {class_label} due to insufficient samples for clustering\")\n",
    "                    continue\n",
    "                print(f\"[client {self.cid}] start the Kmean-Clustering  \")\n",
    "                #print(f\"== [Client {self.cid}] before Kmeans CUDA: allocated {torch.cuda.memory_allocated() // (1024*1024)} MB, reserved {torch.cuda.memory_reserved() // (1024*1024)} MB\")\n",
    "                kmeans = KMeans(n_clusters=k, init=centroids, n_init=1, max_iter=1, algorithm=\"elkan\", random_state=42)\n",
    "                kmeans.fit(features_class)\n",
    "                cluster_labels = kmeans.labels_\n",
    "                centers = kmeans.cluster_centers_\n",
    "                if len(np.unique(cluster_labels)) > 1:\n",
    "                    avg_sil = silhouette_score(features_class, cluster_labels)\n",
    "                else:\n",
    "                    avg_sil = -1.0\n",
    "                avg_silhouette_scores[class_label] = float(avg_sil)\n",
    "                #for meta, cid in zip(metas_class, cluster_labels):\n",
    "                #    meta['cluster_id'] = int(cid)                    \n",
    "                print(f\"== [Client {self.cid}] CUDA: After Kmeans allocated {torch.cuda.memory_allocated() // (1024*1024)} MB, reserved {torch.cuda.memory_reserved() // (1024*1024)} MB\")\n",
    "                print(f\"[client {self.cid}] Preparing for the evaluation function\")\n",
    "                counts = np.bincount(cluster_labels, minlength=k).astype(float)\n",
    "                cluster_list = []\n",
    "                for idx in range(k):\n",
    "                        cluster_list.append({\n",
    "                        \"centroid\": centers[idx].tolist(),\n",
    "                        \"count\": counts[idx]\n",
    "                        })\n",
    "                per_class_cluster_data[class_label] = cluster_list\n",
    "            centroids = []\n",
    "            counts = []\n",
    "            class_labels = []\n",
    "            cluster_indices = []\n",
    "            for class_label, cluster_list in per_class_cluster_data.items():\n",
    "                for cluster_idx, entry in enumerate(cluster_list):\n",
    "                    centroids.append(entry[\"centroid\"])    \n",
    "                    counts.append(entry[\"count\"])\n",
    "                    class_labels.append(class_label)\n",
    "                    cluster_indices.append(cluster_idx)\n",
    "\n",
    "            centroids_array = np.array(centroids, dtype=np.float32)           # shape (N, D)\n",
    "            counts_array = np.array(counts, dtype=np.float32)                 # shape (N,)\n",
    "            class_labels_array = np.array(class_labels, dtype=np.int32)       # shape (N,)\n",
    "            cluster_indices_array = np.array(cluster_indices, dtype=np.int32) # shape (N,) \n",
    "            print(f\"[client {self.cid}] building up the metrics \") \n",
    "            print(f\"== [Client {self.cid}] after building the Per_class_cluster CUDA: allocated {torch.cuda.memory_allocated() // (1024*1024)} MB, reserved {torch.cuda.memory_reserved() // (1024*1024)} MB\")\n",
    "            #metrics = {\"cluster_data\": json.dumps({int(k): v for k, v in per_class_cluster_data.items()})}\n",
    "            print(f\"== [Client {self.cid}] after building the metrics CUDA: allocated {torch.cuda.memory_allocated() // (1024*1024)} MB, reserved {torch.cuda.memory_reserved() // (1024*1024)} MB\")\n",
    "            #dummy_array = np.zeros((1, 1), dtype=np.float32)\n",
    "            #self.save_state()\n",
    "            \n",
    "            tot_samples = sum([len(class_feature_map[c]) for c in per_class_cluster_data])\n",
    "            print(f\"== [Client {self.cid}] After saving the state and preparing the Eval cycle parameters CUDA: allocated {torch.cuda.memory_allocated() // (1024*1024)} MB, reserved {torch.cuda.memory_reserved() // (1024*1024)} MB\")\n",
    "            return [centroids_array, counts_array, class_labels_array, cluster_indices_array], tot_samples, {\"avg_silhouette_scores\": json.dumps(avg_silhouette_scores)}  \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(\"❌ ERROR in client `fit()`:\")\n",
    "            traceback.print_exc()\n",
    "            raise e  # Let Flower fail visibly\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        #self.load_state()\n",
    "        print(f\"[Client {self.cid}] evaluate() called.\")\n",
    "        # Use current centroids from latest fit (already set by previous round)\n",
    "        if \"centroids\" not in config:\n",
    "            print(f\"[Client {self.cid}] No centroids provided in config for evaluation.\")\n",
    "            return 0.0, 0, {}  # Graceful exit with defaults\n",
    "\n",
    "        # Parse centroids from config\n",
    "        try:\n",
    "            centroids_dict = json.loads(config[\"centroids\"])\n",
    "            centroids_dict = {int(k): np.array(v, dtype=np.float32) for k, v in centroids_dict.items()}\n",
    "\n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            print(f\"[Client {self.cid}] Error parsing centroids: {e}\")\n",
    "            return 0.0, 0, {}  # Handle parsing errors gracefully\n",
    "\n",
    "        # Make sure we have features and cluster labels\n",
    "        if self.features is None :\n",
    "            print(f\"[Client {self.cid}] No features or cluster_labels available.\")\n",
    "            return 0.0, 0, {}\n",
    "\n",
    "        # Compute inertia: sum of squared distances to closest centroid for each point\n",
    "        from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "        class_inertia = {}\n",
    "        class_cluster_sizes = {}\n",
    "        total_samples = 0\n",
    "        class_feature_map = defaultdict(list)\n",
    "        class_meta_map = defaultdict(list)\n",
    "\n",
    "        for f, m in zip(self.features, self.metas):\n",
    "                    class_label = m['original_label']\n",
    "                    class_feature_map[class_label].append(f)\n",
    "                    class_meta_map[class_label].append(m)\n",
    "        for class_label in class_feature_map:\n",
    "            if class_label not in centroids_dict:\n",
    "                continue\n",
    "            features_class = np.stack(class_feature_map[class_label])\n",
    "            k = centroids_dict[class_label].shape[0]\n",
    "            centers = centroids_dict[class_label]\n",
    "            assignments = pairwise_distances_argmin(features_class, centers)\n",
    "            # Inertia: sum of squared distances from each sample to assigned centroid\n",
    "            inertia = np.sum((features_class - centers[assignments]) ** 2)\n",
    "            class_inertia[class_label] = float(inertia)\n",
    "            # Cluster sizes\n",
    "            sizes = np.bincount(assignments, minlength=k)\n",
    "            \n",
    "            class_cluster_sizes[class_label] = {int(idx): int(sz) for idx, sz in enumerate(sizes)}\n",
    "            total_samples += len(features_class)\n",
    "        \n",
    "        metrics = {\n",
    "            \"inertia\": float(inertia),\n",
    "            \"cluster_sizes\": json.dumps(class_cluster_sizes)\n",
    "        }\n",
    "        return float(sum(class_inertia.values())), total_samples, metrics\n",
    "\n",
    "\n",
    "    def build_clusters_by_class(self, final_clusters,final_info):\n",
    "            clusters_by_class = defaultdict(list)\n",
    "            for cluster, info in zip(final_clusters, final_info):\n",
    "            \n",
    "                if not cluster or \"original_label\" not in cluster[0]:\n",
    "                    print(\"[DEBUG] Skipping malformed or empty cluster\")\n",
    "                    continue\n",
    "\n",
    "                # Dynamically get the class ID from the first meta in the cluster\n",
    "                class_id = cluster[0][\"original_label\"]\n",
    "    \n",
    "                # Dynamically retrieve the class name from your mapping\n",
    "                class_name = self.label_to_classname[class_id]\n",
    "                cluster_id = info[\"cluster_id\"]\n",
    "                cluster_size = len(cluster)\n",
    "                # Sort cluster by CLIP score, highest first\n",
    "                sorted_cluster = sorted(cluster, key=lambda m: m[\"clip_score\"], reverse=True)\n",
    "                \n",
    "                # Optional: skip clusters where all scores are below threshold (e.g., 0.6)\n",
    "                #if all(m[\"clip_score\"] < 0.6 for m in sorted_cluster):\n",
    "                #    continue\n",
    "               # print(f\"[DEBUG Client {self.cid}]  Class '{class_name}' (ID {class_id}), Cluster {cluster_id}:\")\n",
    "               # print(f\"[DEBUG Client {self.cid}]         Size: {cluster_size}, Unique images: {unique_imgs}, Mean CLIP score: {mean_clip_score:.3f}\")\n",
    "               # print(f\"[DEBUG Client {self.cid}]         Info summary: {info}\")\n",
    "                # Append this sorted cluster and its info to the corresponding class grouping\n",
    "                clusters_by_class[class_name].append((sorted_cluster, {\"cluster_id\": cluster_id}))\n",
    "                print(f\"Accepted cluster: {class_name} | CLIP scores: {[m['clip_score'] for m in sorted_cluster]}\")\n",
    "\n",
    "            return clusters_by_class\n",
    "    \n",
    "############################### Visualization Helper functions ##########################\n",
    "    def plot_cluster_4x4(self, cluster, cluster_id, class_label):\n",
    "        # Ensure output directory exists\n",
    "        out_dir = \"cluster_visualizations\"\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        # Build an informative, safe filename\n",
    "        fname = f\"client_{self.cid}_class_{class_label}_cluster_{cluster_id}.png\"\n",
    "        save_path = os.path.join(out_dir, fname)\n",
    "        print(f\"Saving: {fname} | Class label: {class_label}, Cluster size: {len(cluster)}\")\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        plt.suptitle(f\"Class {class_label} | Cluster {cluster_id} | {len(cluster)} items\")\n",
    "        for i, meta in enumerate(cluster[:16]):\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            img = Image.open(meta['img_path']).convert(\"RGB\")\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(\n",
    "            f\"ImgID: {meta['original_image_index']}\\n\"\n",
    "            f\"Score: {meta['clip_score']:.2f}\\n\"\n",
    "            f\"Clip class: {meta['clip_class']}\", fontsize=8\n",
    "            )\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "    def draw_arrow_on_image(self, ax, xy_from, xy_to, color='yellow', width=2, mutation_scale=15):\n",
    "        \"\"\"Draws an arrow from xy_from to xy_to on a matplotlib axis.\"\"\"\n",
    "        ax.annotate(\n",
    "            '', xy=xy_to, xytext=xy_from,\n",
    "            arrowprops=dict(\n",
    "                arrowstyle='->',\n",
    "                color=color,\n",
    "                lw=width,\n",
    "                shrinkA=0,\n",
    "                shrinkB=0,\n",
    "                mutation_scale=mutation_scale\n",
    "            ),\n",
    "            annotation_clip=False\n",
    "        )\n",
    "\n",
    "    def create_mask_overlay_from_original(self, original_img_path, mask_img, alpha=0.6, mask_color=(255, 180, 0)):\n",
    "        \"\"\" Overlay a binary mask onto the original full image.\"\"\"\n",
    "        import cv2  # Ensure cv2 is imported at top if not\n",
    "        orig = np.array(Image.open(original_img_path).convert(\"RGB\")).copy()\n",
    "        mask = np.array(mask_img)\n",
    "        if mask.max() > 1:\n",
    "           mask_bin = (mask[..., 0] > 0).astype(np.uint8)\n",
    "        else:\n",
    "            mask_bin = mask[..., 0]\n",
    "        mask_rgb = np.zeros_like(orig)\n",
    "        mask_rgb[mask_bin == 1] = mask_color\n",
    "        out = cv2.addWeighted(mask_rgb, alpha, orig, 1 - alpha, 0)\n",
    "        return Image.fromarray(out)\n",
    "\n",
    "\n",
    "    def visualize_clusters_with_overlay_and_arrow(self, clusters_by_class, max_per_cluster=4):\n",
    "        \"\"\" Visualizes each cluster with segment (left) and overlay on original image (right), with arrow.\"\"\"\n",
    "        for class_name, cluster_info_list in clusters_by_class.items():\n",
    "            n_clusters = len(cluster_info_list)\n",
    "            fig, axes = plt.subplots(n_clusters, max_per_cluster, figsize=(5 * max_per_cluster, 4 * n_clusters))\n",
    "            if n_clusters == 1:\n",
    "                axes = np.expand_dims(axes, 0)\n",
    "            plt.suptitle(f\"Class: {class_name} Clusters (sorted by CLIP saliency)\", fontsize=16)\n",
    "\n",
    "            for r, (cluster, info) in enumerate(cluster_info_list):\n",
    "                for c in range(max_per_cluster):\n",
    "                    ax = axes[r, c] if n_clusters > 1 else axes[0, c]\n",
    "                    try:\n",
    "                        meta = cluster[c]\n",
    "                    except IndexError:\n",
    "                        ax.axis('off')\n",
    "                        continue\n",
    "\n",
    "                # Load the segment image as saved (RGB)\n",
    "                    seg_img = Image.open(meta['img_path']).convert(\"RGB\")\n",
    "                    seg_np = np.array(seg_img)\n",
    "\n",
    "                # Derive binary mask (used only for overlay)\n",
    "                    import cv2\n",
    "                    gray = cv2.cvtColor(seg_np, cv2.COLOR_RGB2GRAY)\n",
    "                    mask_only = np.where(gray > 5, 255, 0).astype(np.uint8)\n",
    "                    mask_only = np.expand_dims(mask_only, axis=-1)\n",
    "\n",
    "                # Load the original image and create overlay\n",
    "                    orig_img_path = meta.get('original_image_path')  # Assume this field exists in meta\n",
    "                    overlay_img = self.create_mask_overlay_from_original(orig_img_path, mask_only, alpha=0.6)\n",
    "\n",
    "                # Resize both views\n",
    "                    thumb_segment = seg_img.resize((64, 64), Image.LANCZOS)\n",
    "                    thumb_overlay = overlay_img.resize((128, 128), Image.LANCZOS)\n",
    "\n",
    "                # Compose side-by-side image\n",
    "                    combined = Image.new('RGB', (thumb_segment.width + thumb_overlay.width, thumb_overlay.height), (255, 255, 255))\n",
    "                    combined.paste(thumb_segment, (0, 0))\n",
    "                    combined.paste(thumb_overlay, (thumb_segment.width, 0))\n",
    "\n",
    "                # Show in subplot\n",
    "                    ax.imshow(combined)\n",
    "                    ax.axis('off')\n",
    "\n",
    "                # Draw arrow between segment and overlay\n",
    "                    arrow_start = (thumb_segment.width // 2, thumb_overlay.height // 2)\n",
    "                    arrow_end = (thumb_segment.width + thumb_overlay.width // 2, thumb_overlay.height // 2)\n",
    "                    self.draw_arrow_on_image(ax, arrow_start, arrow_end)\n",
    "\n",
    "                # Add title with cluster info\n",
    "                    ax.set_title(f\"CID: {info['cluster_id']} | Score: {meta['clip_score']:.2f} \\n Clip Interpretation: {meta['clip_class']}\", fontsize=9)\n",
    "\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "            plt.savefig(f\"cluster_visualizations/[Client_{self.cid}]Class{class_name}_cluster_segment_overlay_images.png\")\n",
    "            plt.close(fig)\n",
    "    def visualize_clusters_umap_3d(self, structured_clusters):\n",
    "        os.makedirs(\"cluster_visualizations\", exist_ok=True)\n",
    "        for class_label, clusters in structured_clusters.items():\n",
    "            all_feats = []\n",
    "            all_labels = []\n",
    "            for cluster, info in clusters:\n",
    "                cluster_feats = [f for f in self.extract_features_dinov2_from_metas(cluster)]\n",
    "                cluster_id = info['cluster_id']\n",
    "                all_feats.extend(cluster_feats)\n",
    "                all_labels.extend([cluster_id] * len(cluster_feats))\n",
    "\n",
    "            if len(set(all_labels)) < 2:\n",
    "                continue\n",
    "\n",
    "            reducer = umap.UMAP(n_components=3, random_state=42)\n",
    "            reduced = reducer.fit_transform(np.array(all_feats))\n",
    "   \n",
    "            all_labels = np.array(all_labels)\n",
    "            fig = plt.figure(figsize=(10, 8))\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            colors = cm.get_cmap('tab10', np.max(all_labels)+1)\n",
    "            for cluster_id in np.unique(all_labels):\n",
    "                idx = all_labels == cluster_id\n",
    "                ax.scatter(reduced[idx, 0], reduced[idx, 1], reduced[idx, 2],\n",
    "                           label=f\"Cluster {cluster_id}\", alpha=0.6, s=30,\n",
    "                           color=colors(cluster_id))\n",
    "            ax.set_title(f\"[Client {self.cid}] 3D UMAP of Class '{class_label}' by Cluster\")\n",
    "            ax.legend()\n",
    "            ax.view_init(elev=20, azim=135)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"cluster_visualizations/[Client]_{self.cid}UMAP3D_{class_label}.png\")\n",
    "            plt.close(fig)\n",
    "\n",
    "    def extract_features_dinov2_from_metas(self, metas, batch_size=256):\n",
    "        img_tensors = []\n",
    "        feats_accum = []\n",
    "        for i, meta in enumerate(metas):\n",
    "            img = Image.open(meta['img_path']).convert(\"RGB\")\n",
    "            img_tensor = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])(img)\n",
    "            img_tensors.append(img_tensor)\n",
    "            if len(img_tensors) == batch_size or (i == len(metas) - 1):\n",
    "                batch = torch.stack(img_tensors).to(self.device)\n",
    "                with torch.no_grad():\n",
    "                        feats = self.dinov2(batch).cpu().numpy()\n",
    "                feats_accum.extend(feats)\n",
    "                del batch\n",
    "                torch.cuda.empty_cache()\n",
    "                img_tensors = []\n",
    "        return feats_accum        \n",
    "        #if not img_tensors:\n",
    "#########################################################################################\n",
    "    def train_cavs_and_tcav(self):\n",
    "        \n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        inception_model = inception_v3(weights='IMAGENET1K_V1').to(device)\n",
    "        inception_model.eval()\n",
    "\n",
    "        inception_features = {}\n",
    "        gradients = {}\n",
    "        metrics = {}\n",
    "        def hook_fn(module, input, output):\n",
    "            inception_features['mixed_8'] = output.detach()\n",
    "\n",
    "        def save_gradient(module, grad_input, grad_output):\n",
    "            gradients['mixed_8'] = grad_output[0]\n",
    "\n",
    "        inception_model.Mixed_7b.register_forward_hook(hook_fn)\n",
    "        inception_model.Mixed_7b.register_backward_hook(save_gradient)\n",
    "\n",
    "        inception_preproc = transforms.Compose([\n",
    "            transforms.Resize((299, 299)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        def extract_mixed8_features(segment_metas):\n",
    "            images = []\n",
    "            feats = []\n",
    "            for meta in segment_metas:\n",
    "                img_path = meta['img_path']\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img_tensor = inception_preproc(img)\n",
    "                images.append(img_tensor)\n",
    "            if not images:\n",
    "                return np.zeros((0, 1280))\n",
    "            batch_size = 512\n",
    "            for i in range(0, len(images), batch_size):\n",
    "                batch=torch.stack(images[i:i + batch_size]).to(self.device)\n",
    "                with torch.no_grad():\n",
    "                    _ = inception_model(batch)\n",
    "                    batch_feats = inception_features['mixed_8'].mean(dim=[2, 3])\n",
    "                feats.append(batch_feats.cpu().numpy())    \n",
    "                torch.cuda.empty_cache()\n",
    "            return np.concatenate(feats, axis=0)\n",
    "\n",
    "        def calculate_cav(concept_features, random_features):\n",
    "            X = np.concatenate([concept_features, random_features], axis=0)\n",
    "            y = np.array([1]*len(concept_features) + [0]*len(random_features))\n",
    "            clf = LogisticRegression(max_iter=1000)\n",
    "            clf.fit(X, y)\n",
    "            cav = clf.coef_[0]\n",
    "            cav = cav / np.linalg.norm(cav)\n",
    "            mean_pos = np.mean(np.dot(concept_features, cav))\n",
    "            mean_neg = np.mean(np.dot(random_features, cav))\n",
    "            if mean_pos < mean_neg:\n",
    "                cav = -cav\n",
    "            return cav \n",
    "\n",
    "        def get_mixed8_gradients(img, target_class_idx):\n",
    "            inception_features.clear()\n",
    "            gradients.clear()\n",
    "            tensor = inception_preproc(img).unsqueeze(0).to(self.device)\n",
    "            tensor.requires_grad_(True)\n",
    "            output = inception_model(tensor)\n",
    "            target_logit = output[:, target_class_idx]\n",
    "            inception_model.zero_grad()\n",
    "            target_logit.backward()\n",
    "            grad = gradients['mixed_8'].detach().cpu().numpy().squeeze()\n",
    "            grad_pooled = grad.mean(axis=(1,2))\n",
    "            return grad_pooled\n",
    "\n",
    "        def compute_tcav_score_for_class(class_images, cav, target_class_idx):\n",
    "            pos = 0\n",
    "            for img in class_images:\n",
    "                grad_pooled = get_mixed8_gradients(img, target_class_idx)\n",
    "                grad_pooled = grad_pooled / np.linalg.norm(grad_pooled)\n",
    "                if np.dot(grad_pooled, cav) > 0:\n",
    "                    pos += 1\n",
    "            return pos / len(class_images)\n",
    "\n",
    "        def load_test_images_by_class(test_dir):\n",
    "            class_images = {}\n",
    "            for class_label in os.listdir(test_dir):\n",
    "                if class_label.startswith('.'):\n",
    "                    continue\n",
    "                class_path = os.path.join(test_dir, class_label)\n",
    "                if not os.path.isdir(class_path):\n",
    "                    continue\n",
    "                imgs = []\n",
    "                for fname in os.listdir(class_path):\n",
    "                    if fname.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                        img = Image.open(os.path.join(class_path, fname)).convert('RGB')\n",
    "                        imgs.append(img)\n",
    "                class_images[class_label] = imgs\n",
    "            return class_images\n",
    "\n",
    "        def plot_tcav_heatmap(tcav_matrix, class_labels, cluster_labels, client_id, out_dir=\"cluster_visualizations\", concept_class=\"???\"):\n",
    "            \"\"\"\n",
    "            tcav_matrix: np.ndarray of shape (num_clusters, num_classes)\n",
    "            class_labels: list of class names (columns)\n",
    "            cluster_labels: list of cluster names/ids (rows)\n",
    "            client_id: client numeric id\n",
    "            out_dir: directory to save the output image\n",
    "            \"\"\"\n",
    "            import matplotlib\n",
    "            import matplotlib.pyplot as plt\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            fig, ax = plt.subplots(figsize=(1.2 * len(class_labels) + 2, 0.8 * len(cluster_labels) + 3))\n",
    "            cmap = matplotlib.colors.LinearSegmentedColormap.from_list('red_green', ['red', 'yellow', 'green'])\n",
    "            cax = ax.imshow(tcav_matrix, cmap=cmap, vmin=0., vmax=1.)\n",
    "\n",
    "            for i in range(tcav_matrix.shape[0]):\n",
    "                for j in range(tcav_matrix.shape[1]):\n",
    "                    val = tcav_matrix[i, j]\n",
    "                    ax.text(j, i, f\"{val:.2f}\", va='center', ha='center',\n",
    "                            color=\"black\" if val < 0.5 else \"white\", fontsize=10, fontweight='bold')\n",
    "            ax.set_xticks(np.arange(len(class_labels)))\n",
    "            ax.set_yticks(np.arange(len(cluster_labels)))\n",
    "            ax.set_xticklabels(class_labels, rotation=45, ha=\"right\", fontsize=12)\n",
    "            ax.set_yticklabels(cluster_labels, fontsize=12)\n",
    "            ax.set_xlabel(\"Class label\")\n",
    "            ax.set_ylabel(\"Concept (Cluster)\")\n",
    "            plt.title(f\"TCAV class {concept_class} Concepts Contribution\\nClient {client_id}\", fontsize=15, pad=25)\n",
    "            plt.colorbar(cax, ax=ax, fraction=0.045)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(out_dir, f\"TCAV_heatmap_class_{concept_class}_client{client_id}.png\"))\n",
    "            plt.close(fig)\n",
    "\n",
    "        final_clusters = []\n",
    "        final_info = []\n",
    "        per_class_clusters = defaultdict(lambda: defaultdict(list))\n",
    "        for meta in self.metas:\n",
    "            class_label = meta['original_label']\n",
    "            cluster_id = meta['cluster_id']\n",
    "            per_class_clusters[class_label][cluster_id].append(meta)\n",
    "\n",
    "        for class_label, cluster_dict in per_class_clusters.items():\n",
    "            metas_class = []\n",
    "            for cluster in cluster_dict.values():\n",
    "                metas_class.extend(cluster)\n",
    "            num_discovery_images = len(set(m['original_image_index'] for m in metas_class))\n",
    "            print(f\"{num_discovery_images} unique discovery images for class {class_label}\")\n",
    "\n",
    "            for c_id, cluster in cluster_dict.items():\n",
    "                img_indices = [m['original_image_index'] for m in cluster]\n",
    "                unique_imgs = set(img_indices)\n",
    "                cluster_size = len(cluster)\n",
    "                num_unique_imgs = len(unique_imgs)\n",
    "                clip_scores = [m['clip_score'] for m in cluster]\n",
    "                mean_clip_score = np.mean(clip_scores) if clip_scores else 0\n",
    "                keep = num_unique_imgs >= 10 or (cluster_size >= 30 and mean_clip_score > 0.75)\n",
    "                print(\n",
    "            f\"Class {class_label} Cluster {c_id}: \"\n",
    "            f\"size={cluster_size}, unique_imgs={num_unique_imgs}, \"\n",
    "            f\"mean_clip_score={mean_clip_score:.3f}, keep={keep}\")\n",
    "                for meta in cluster:\n",
    "                    meta[\"cluster_id\"] = c_id\n",
    "                final_clusters.append(cluster)\n",
    "                final_info.append({\n",
    "                \"class_label\": class_label,\n",
    "                \"cluster_id\": c_id,\n",
    "                \"num_members\": cluster_size,\n",
    "                \"num_images\": num_unique_imgs,\n",
    "                \"mean_clip_score\": mean_clip_score\n",
    "                })\n",
    "        \n",
    "        clusters_by_class = self.build_clusters_by_class(final_clusters,final_info)\n",
    "        for class_label, clusters in clusters_by_class.items():\n",
    "            for cid, (cluster_metas, info) in enumerate(clusters):\n",
    "                self.plot_cluster_4x4(cluster_metas, cid, class_label)\n",
    "        self.visualize_clusters_with_overlay_and_arrow(clusters_by_class, max_per_cluster=4)\n",
    "        # 3D UMAP Visualization per class\n",
    "        self.visualize_clusters_umap_3d(clusters_by_class)\n",
    "\n",
    "        # Construct cluster CAVs\n",
    "        cluster_cavs = {}\n",
    "        cav_results = {}    \n",
    "        for class_label, clusters in clusters_by_class.items():\n",
    "            for cluster, info in clusters:\n",
    "                cid = info['cluster_id']\n",
    "                other_same_class = [m for c, i in clusters if i['cluster_id'] != cid for m in c]\n",
    "                other_classes = [m for l, cls in clusters_by_class.items() if l != class_label for c, _ in cls for m in c]\n",
    "                n_pos = len(cluster)\n",
    "                n_same = min(n_pos // 2, len(other_same_class))\n",
    "                n_other = min(n_pos - n_same, len(other_classes))\n",
    "                if n_same + n_other == 0:\n",
    "                    continue\n",
    "                neg_samples = random.sample(other_same_class, n_same) + random.sample(other_classes, n_other)\n",
    "                pos_feats = extract_mixed8_features(cluster)\n",
    "                neg_feats = extract_mixed8_features(neg_samples)\n",
    "                cav = calculate_cav(pos_feats, neg_feats)\n",
    "                cluster_cavs[(class_label, cid)] = cav\n",
    "                cav_results[f\"{class_label}_{cid}\"] = {\n",
    "                    \"cav\": cav.tolist(),\n",
    "                    \"count\": len(cluster)}\n",
    "                metrics[\"cav_results\"] = json.dumps(cav_results)\n",
    "            print(f\"all the related CAV of Class {class_label} was successfully generated : \\n {cluster_cavs} \\n\")\n",
    "          \n",
    "        test_dir = '/gpfs/helios/home/mahmouds/Thesis/Test'\n",
    "        image_dir= '/gpfs/helios/home/mahmouds/Thesis/data/ILSVRC2012/segmentation'\n",
    "        class_to_inception_idx = {\n",
    "            'basketball': 816,\n",
    "            #'corn ears': 499,\n",
    "            #'electric ray': 445,\n",
    "            'mountain bike': 162,\n",
    "            'moving van': 191\n",
    "            #'soccer ball': 817\n",
    "        }\n",
    "        test_images = load_test_images_by_class(test_dir)\n",
    "\n",
    "        #for (class_label, cid), cav in cluster_cavs.items():\n",
    "        #    if class_label not in test_images or class_label not in class_to_inception_idx:\n",
    "        #        continue\n",
    "        #    score = compute_tcav_score_for_class(test_images[class_label], cav, class_to_inception_idx[class_label])\n",
    "        #    print(f\" [Client {self.cid}] TCAV score for class {class_label} cluster {cid}: {score:.2f}\")\n",
    "        #    #### ---- I need to report properly the test image with the contributed clusters ------####\n",
    "        # ----- Build list of all clusters and class labels for the matrix dimensions\n",
    "        clusters = list(cluster_cavs.keys())\n",
    "        cluster_labels = [f\"{self.label_to_classname.get(cl, cl)}-C{cid}\" for cl, cid in clusters]\n",
    "        class_labels = sorted(test_images.keys())\n",
    "        unique_classes = sorted(set(cl for cl, _ in clusters))\n",
    "        # Initialize the matrix\n",
    "        tcav_matrix = np.zeros((len(clusters), len(class_labels)))\n",
    "\n",
    "# Fill matrix: rows=clusters, cols=class labels\n",
    "        for i, (class_label, cid) in enumerate(clusters):\n",
    "            for j, test_class in enumerate(class_labels):\n",
    "                if test_class not in test_images or class_label not in class_to_inception_idx:\n",
    "                    tcav_matrix[i, j] = np.nan  # gray if missing\n",
    "                    continue\n",
    "                score = compute_tcav_score_for_class(\n",
    "                    test_images[test_class],\n",
    "                    cluster_cavs[(class_label, cid)],\n",
    "                    class_to_inception_idx[test_class]\n",
    "                )\n",
    "                tcav_matrix[i, j] = score\n",
    "        for concept_class in unique_classes:\n",
    "            rows = [i for i, (cl, _) in enumerate(clusters) if cl == concept_class]\n",
    "            if not rows:\n",
    "                continue  # No clusters for this class, skip\n",
    "            submatrix = tcav_matrix[rows, :]\n",
    "            sub_cluster_labels = [cluster_labels[i] for i in rows]\n",
    "            \n",
    "        # After the loop, immediately call:\n",
    "            #plot_tcav_heatmap(tcav_matrix, class_labels, cluster_labels, client_id=self.cid)\n",
    "            plot_tcav_heatmap(submatrix, class_labels, sub_cluster_labels, client_id=self.cid, out_dir=\"cluster_visualizations\",concept_class=concept_class)\n",
    "            print(f\"[Client {self.cid}] Saved TCAV class{concept_class} concepts heatmap to cluster_visualizations/TCAV_heatmap_client{self.cid}.png\")\n",
    "        dummy_array = np.zeros((self.k, self.features.shape[1]), dtype=np.float32)\n",
    "        #print(f\"this is the metrics after the local cav: {metrics}\")\n",
    "        return cav_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be005451-bf8e-4f20-91b3-b457fb5da81b",
   "metadata": {},
   "source": [
    "### Main funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec17a738-8c54-4d1e-a771-53b4cae948b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/space/software/cluster_software/spack/linux-rhel9-x86_64/gcc-9.2.0/python-3.12.3-jfsvfhxwrihwyloazioovxwqtuwcg6qf/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=2478198) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "!export FLWR_LOG_LEVEL=DEBUG\n",
    "!export GRPC_VERBOSITY=DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e14a14d-a998-4915-9ffd-98bf8e4d8b5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed 15 centroids for class 0\n",
      "Computed 15 centroids for class 1\n",
      "Computed 15 centroids for class 2\n",
      "\n",
      "Total classes initialized: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "WARNING:flwr:DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=50, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Starting SAM2 segmentation and saving segments with metadata for client 0 ...\n",
      "[Client 0] Segmentation done. Starting feature extraction...\n",
      "🔧 Starting SAM2 segmentation and saving segments with metadata for client 1 ...\n",
      "[Client 1] Segmentation done. Starting feature extraction...\n",
      "🔧 Starting SAM2 segmentation and saving segments with metadata for client 2 ...\n",
      "[Client 2] Segmentation done. Starting feature extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 18:37:27,083\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'node:172.16.10.124': 1.0, 'accelerator_type:V100': 1.0, 'CPU': 64.0, 'memory': 468548713472.0, 'object_store_memory': 5368709120.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 4, 'num_gpus': 0.25}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 4 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.0, {}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Global evaluation for round 0 skipped (no global model).\n",
      "[Strategy] configure_fit called for round 1\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=2482602)\u001b[0m 2025-08-16 18:39:25.335111: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[36m(pid=2482601)\u001b[0m 2025-08-16 18:39:25.363557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=2482602)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[36m(pid=2482602)\u001b[0m E0000 00:00:1755358765.404786 2482602 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=2482602)\u001b[0m E0000 00:00:1755358765.417111 2482602 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=2482602)\u001b[0m W0000 00:00:1755358765.448827 2482602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=2482602)\u001b[0m W0000 00:00:1755358765.448867 2482602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=2482602)\u001b[0m W0000 00:00:1755358765.448870 2482602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=2482602)\u001b[0m W0000 00:00:1755358765.448873 2482602 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[36m(pid=2482602)\u001b[0m 2025-08-16 18:39:25.457062: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=2482602)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Starting initialization...\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Attempting to load pickle file...\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Pickle file loaded successfully\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[36m(pid=2482603)\u001b[0m 2025-08-16 18:39:25.376851: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(pid=2482604)\u001b[0m 2025-08-16 18:39:25.375767: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=2482601)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=2482601)\u001b[0m E0000 00:00:1755358765.398504 2482601 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=2482601)\u001b[0m E0000 00:00:1755358765.409687 2482601 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=2482603)\u001b[0m W0000 00:00:1755358765.479990 2482603 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=2482603)\u001b[0m 2025-08-16 18:39:25.493165: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=2482603)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   warnings.warn(\"xFormers is available (Attention)\")\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] ThesisKMeansClient created successfully\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2]  Class 0: 1396 segments\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] Preparing for the evaluation function\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2]  Class 1: 386 segments\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] Preparing for the evaluation function\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2]  Class 2: 306 segments\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] Preparing for the evaluation function\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0] Starting initialization...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0] Attempting to load pickle file...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0] Pickle file loaded successfully\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0] Data extracted: features=torch.Size([2157, 384]), labels=2157, metas=2157\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 0 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2157, 384])\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 0 Labels: <class 'torch.Tensor'>, length: 2157\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 0 Metas: <class 'list'>, length: 2157\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.0, {}, 155.01158217713237)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 1] Max centroid shift: 66.70\n",
      "[Server] Global evaluation for round 1 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   warnings.warn(\"xFormers is available (SwiGLU)\")\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   warnings.warn(\"xFormers is available (Attention)\")\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   warnings.warn(\"xFormers is available (Block)\")\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0] evaluate() called.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0] ThesisKMeansClient created successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0]  Class 2: 284 segments\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] start the Kmean-Clustering  \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] Preparing for the evaluation function\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] building up the metrics \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 2\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1] evaluate() called.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2]  Class 2: 306 segments\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] start the Kmean-Clustering  \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.0, {}, 163.17628674209118)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 2] Max centroid shift: 21.31\n",
      "[Server] Global evaluation for round 2 skipped (no global model).\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 3\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1]  Class 2: 283 segments\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] start the Kmean-Clustering  \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] Preparing for the evaluation function\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.0, {}, 171.37281896919012)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "[Round 3] Max centroid shift: 13.08\n",
      "[Server] Global evaluation for round 3 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0]  Class 2: 284 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "[Strategy] configure_fit called for round 4\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 0] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.0, {}, 179.68220000714064)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 4] Max centroid shift: 12.21\n",
      "[Server] Global evaluation for round 4 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0] evaluate() called.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1]  Class 2: 283 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 1] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1] evaluate() called.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "[Strategy] configure_fit called for round 5\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 2] building up the metrics \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2]  Class 0: 1396 segments\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 2] start the Kmean-Clustering  \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 0] Preparing for the evaluation function\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.0, {}, 188.036489456892)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 5] Max centroid shift: 10.01\n",
      "[Server] Global evaluation for round 5 skipped (no global model).\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] evaluate() called.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] evaluate() called.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 6\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 2] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0]  Class 0: 1467 segments\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] start the Kmean-Clustering  \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (6, 0.0, {}, 196.0726229660213)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "[Round 6] Max centroid shift: 5.76\n",
      "[Server] Global evaluation for round 6 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] evaluate() called.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1]  Class 2: 283 segments\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] start the Kmean-Clustering  \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "[Strategy] configure_fit called for round 7\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (7, 0.0, {}, 204.33577162399888)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 1] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n",
      "[Round 7] Max centroid shift: 5.28\n",
      "[Server] Global evaluation for round 7 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2]  Class 2: 306 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 8\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1]  Class 1: 372 segments\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 1] start the Kmean-Clustering  \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 1] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 1] Preparing for the evaluation function\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (8, 0.0, {}, 212.22057984769344)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 8] Max centroid shift: 5.13\n",
      "[Server] Global evaluation for round 8 skipped (no global model).\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] evaluate() called.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "[Strategy] configure_fit called for round 9\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] building up the metrics \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2]  Class 0: 1396 segments\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] start the Kmean-Clustering  \u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (9, 0.0, {}, 220.42555958405137)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "[Round 9] Max centroid shift: 4.43\n",
      "[Server] Global evaluation for round 9 skipped (no global model).\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0] evaluate() called.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] evaluate() called.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 1] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1]  Class 2: 283 segments\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 1] start the Kmean-Clustering  \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 1] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "[Strategy] configure_fit called for round 10\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] evaluate() called.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (10, 0.0, {}, 228.58195739239454)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "[Round 10] Max centroid shift: 2.00\n",
      "[Server] Global evaluation for round 10 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 1] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1]  Class 2: 283 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 1] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 1] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 1] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "[Strategy] configure_fit called for round 11\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (11, 0.0, {}, 236.5060632005334)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "[Round 11] Max centroid shift: 2.06\n",
      "[Server] Global evaluation for round 11 skipped (no global model).\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0]  Class 2: 284 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 0] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 12]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 12\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1]  Class 0: 1506 segments\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 1] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0]  Class 0: 1467 segments\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 1] Preparing for the evaluation function\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 1] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (12, 0.0, {}, 244.34801487624645)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "[Round 12] Max centroid shift: 1.98\n",
      "[Server] Global evaluation for round 12 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 13]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "[Strategy] configure_fit called for round 13\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2]  Class 2: 306 segments\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] start the Kmean-Clustering  \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] building up the metrics \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (13, 0.0, {}, 252.5059758350253)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "[Round 13] Max centroid shift: 0.99\n",
      "[Server] Global evaluation for round 13 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1] evaluate() called.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 14]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0] evaluate() called.\n",
      "[Strategy] configure_fit called for round 14\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1]  Class 2: 283 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] Starting initialization...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] Attempting to load pickle file...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (14, 0.0, {}, 260.76522148028016)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "[Round 14] Max centroid shift: 1.27\n",
      "[Server] Global evaluation for round 14 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] evaluate() called.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2]  Class 2: 306 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 2] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 2] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 15]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 15\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (15, 0.0, {}, 268.6454196199775)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "[Round 15] Max centroid shift: 1.61\n",
      "[Server] Global evaluation for round 15 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0] evaluate() called.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2]  Class 2: 306 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 16]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 16\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2]  Class 0: 1396 segments\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0]  Class 0: 1467 segments\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 0] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] Preparing for the evaluation function\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (16, 0.0, {}, 276.9594450816512)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "[Round 16] Max centroid shift: 1.21\n",
      "[Server] Global evaluation for round 16 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 17]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 17\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] Starting initialization...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] Attempting to load pickle file...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] Pickle file loaded successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] Data extracted: features=torch.Size([2161, 384]), labels=2161, metas=2161\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 1 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2161, 384])\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 1 Labels: <class 'torch.Tensor'>, length: 2161\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 1 Metas: <class 'list'>, length: 2161\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1]  Class 2: 283 segments\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] start the Kmean-Clustering  \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] Preparing for the evaluation function\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] building up the metrics \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (17, 0.0, {}, 284.98798993974924)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "[Round 17] Max centroid shift: 0.79\n",
      "[Server] Global evaluation for round 17 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0] ThesisKMeansClient created successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0] evaluate() called.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1] Starting initialization...\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1] Attempting to load pickle file...\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1] Pickle file loaded successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1] Data extracted: features=torch.Size([2161, 384]), labels=2161, metas=2161\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 1 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2161, 384])\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 1 Labels: <class 'torch.Tensor'>, length: 2161\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 1 Metas: <class 'list'>, length: 2161\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2]  Class 2: 306 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 18]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] evaluate() called.\n",
      "[Strategy] configure_fit called for round 18\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (18, 0.0, {}, 292.95199923962355)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "[Round 18] Max centroid shift: 0.68\n",
      "[Server] Global evaluation for round 18 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1]  Class 2: 283 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] evaluate() called.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 19]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 19\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1]  Class 0: 1506 segments\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1]  Class 1: 372 segments\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1]  Class 2: 283 segments\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1] evaluate() called.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 1] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (19, 0.0, {}, 301.7343433983624)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 2] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "[Round 19] Max centroid shift: 0.65\n",
      "[Server] Global evaluation for round 19 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 20]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 20\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0]  Class 2: 284 segments\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] start the Kmean-Clustering  \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 0] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] Preparing for the evaluation function\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 0] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 0] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 0] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 1] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (20, 0.0, {}, 309.480045825243)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "[Round 20] Max centroid shift: 0.59\n",
      "[Server] Global evaluation for round 20 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 21]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 21\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0]  Class 2: 284 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 0] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 0] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 0] building up the metrics \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (21, 0.0, {}, 317.24547316879034)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "[Round 21] Max centroid shift: 0.51\n",
      "[Server] Global evaluation for round 21 skipped (no global model).\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0] Starting initialization...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0] Attempting to load pickle file...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0] Pickle file loaded successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0] Data extracted: features=torch.Size([2157, 384]), labels=2157, metas=2157\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 0 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2157, 384])\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 0 Labels: <class 'torch.Tensor'>, length: 2157\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 0 Metas: <class 'list'>, length: 2157\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 22]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2]  Class 2: 306 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0] evaluate() called.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 2] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "[Strategy] configure_fit called for round 22\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (22, 0.0, {}, 325.5608495771885)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "[Round 22] Max centroid shift: 0.55\n",
      "[Server] Global evaluation for round 22 skipped (no global model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2]  Class 2: 306 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] evaluate() called.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 2] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 2] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] evaluate() called.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 23]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 23\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0]  Class 0: 1467 segments\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 0] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] Preparing for the evaluation function\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0]  Class 1: 406 segments\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 0] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] Preparing for the evaluation function\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0]  Class 2: 284 segments\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] start the Kmean-Clustering  \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 0] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] Preparing for the evaluation function\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [client 0] building up the metrics \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 0] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 0] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m == [Client 0] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (23, 0.0, {}, 333.6746831983328)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 23] Max centroid shift: 0.54\n",
      "[Server] Global evaluation for round 23 skipped (no global model).\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0] evaluate() called.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 1] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 1]  Class 2: 283 segments\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 1] start the Kmean-Clustering  \u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 24]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 24\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Still in Clustering mode \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 1] Preparing for the evaluation function\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [client 1] building up the metrics \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m == [Client 1] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 📦 fit() called on client.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Discovered 3 unique classes\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 0] evaluate() called.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] ThesisKMeansClient created successfully\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "[Round 24] Max centroid shift: 0.41\n",
      "Convergence achieved. Switching to TCAV phase.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      fit progress: (24, 0.0, {}, 343.1526975668967)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Global evaluation for round 24 skipped (no global model).\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0]  Class 2: 284 segments\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 0] start the Kmean-Clustering  \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] CUDA: After Kmeans allocated 84 MB, reserved 110 MB\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 0] Preparing for the evaluation function\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [client 0] building up the metrics \u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] after building the Per_class_cluster CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] after building the metrics CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m == [Client 0] After saving the state and preparing the Eval cycle parameters CUDA: allocated 84 MB, reserved 110 MB\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Discovered 3 unique classes\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m [Client 0] evaluate() called.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 25]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Strategy] configure_fit called for round 25\n",
      "[Strategy] Available clients: 3\n",
      "[Server] Sending LOCAL TCAV configs.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m  [CLient 2] is Converged and start constructing the needed Clusters\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] ThesisKMeansClient created successfully\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Starting initialization...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Attempting to load pickle file...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Pickle file loaded successfully\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client 2] Data extracted: features=torch.Size([2088, 384]), labels=2088, metas=2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Initializing with features: <class 'torch.Tensor'>, shape: torch.Size([2088, 384])\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Labels: <class 'torch.Tensor'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m [Client] 2 Metas: <class 'list'>, length: 2088\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m  [CLient 2] is Proceeding for Training CAVs and computing TCAV scores...\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m  [CLient 2] Picking up the nearest 40 instaces to the clusters' centriods...\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 173 unique discovery images for class 0\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 0: size=40, unique_imgs=27, mean_clip_score=0.825, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 1: size=40, unique_imgs=31, mean_clip_score=0.927, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 2: size=40, unique_imgs=31, mean_clip_score=0.539, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 3: size=40, unique_imgs=35, mean_clip_score=0.603, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 4: size=40, unique_imgs=34, mean_clip_score=0.991, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 5: size=40, unique_imgs=36, mean_clip_score=0.605, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 6: size=40, unique_imgs=37, mean_clip_score=0.793, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 7: size=40, unique_imgs=37, mean_clip_score=0.747, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 8: size=40, unique_imgs=33, mean_clip_score=0.962, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 9: size=40, unique_imgs=36, mean_clip_score=0.991, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 10: size=40, unique_imgs=34, mean_clip_score=0.969, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 11: size=40, unique_imgs=35, mean_clip_score=0.986, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 12: size=40, unique_imgs=30, mean_clip_score=0.965, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 13: size=40, unique_imgs=30, mean_clip_score=0.825, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 0 Cluster 14: size=40, unique_imgs=28, mean_clip_score=0.886, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 186 unique discovery images for class 1\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 0: size=38, unique_imgs=34, mean_clip_score=0.627, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 1: size=22, unique_imgs=18, mean_clip_score=0.649, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 2: size=27, unique_imgs=26, mean_clip_score=0.711, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 3: size=10, unique_imgs=7, mean_clip_score=0.717, keep=False\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 4: size=21, unique_imgs=19, mean_clip_score=0.781, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 5: size=23, unique_imgs=22, mean_clip_score=0.581, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 6: size=37, unique_imgs=34, mean_clip_score=0.697, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 7: size=33, unique_imgs=31, mean_clip_score=0.681, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 8: size=20, unique_imgs=17, mean_clip_score=0.578, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 9: size=7, unique_imgs=6, mean_clip_score=0.681, keep=False\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 10: size=40, unique_imgs=31, mean_clip_score=0.751, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 11: size=17, unique_imgs=11, mean_clip_score=0.734, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 12: size=26, unique_imgs=21, mean_clip_score=0.592, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 13: size=22, unique_imgs=21, mean_clip_score=0.660, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 1 Cluster 14: size=31, unique_imgs=29, mean_clip_score=0.662, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m 233 unique discovery images for class 2\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 0: size=23, unique_imgs=23, mean_clip_score=0.820, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 1: size=12, unique_imgs=12, mean_clip_score=0.907, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 2: size=11, unique_imgs=11, mean_clip_score=0.934, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 3: size=14, unique_imgs=13, mean_clip_score=0.731, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 4: size=27, unique_imgs=26, mean_clip_score=0.889, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 5: size=34, unique_imgs=32, mean_clip_score=0.918, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 6: size=21, unique_imgs=18, mean_clip_score=0.596, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 7: size=21, unique_imgs=21, mean_clip_score=0.896, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 8: size=30, unique_imgs=30, mean_clip_score=0.949, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 9: size=27, unique_imgs=24, mean_clip_score=0.648, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 10: size=8, unique_imgs=8, mean_clip_score=0.763, keep=False\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 11: size=27, unique_imgs=26, mean_clip_score=0.888, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 12: size=14, unique_imgs=12, mean_clip_score=0.774, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 13: size=6, unique_imgs=5, mean_clip_score=0.577, keep=False\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Class 2 Cluster 14: size=31, unique_imgs=25, mean_clip_score=0.559, keep=True\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.98974609375, 0.98681640625, 0.9833984375, 0.97998046875, 0.9658203125, 0.96142578125, 0.95849609375, 0.95458984375, 0.9541015625, 0.94873046875, 0.9423828125, 0.94140625, 0.94140625, 0.93798828125, 0.93212890625, 0.9306640625, 0.92529296875, 0.9130859375, 0.90625, 0.90185546875, 0.8994140625, 0.88623046875, 0.884765625, 0.8583984375, 0.8466796875, 0.80126953125, 0.77783203125, 0.7734375, 0.74462890625, 0.67041015625, 0.6630859375, 0.6298828125, 0.61669921875, 0.6123046875, 0.578125, 0.57373046875, 0.57373046875, 0.55419921875, 0.5478515625, 0.541015625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [1.0, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.9990234375, 0.9990234375, 0.9990234375, 0.9990234375, 0.9990234375, 0.9990234375, 0.9990234375, 0.99853515625, 0.998046875, 0.99609375, 0.9951171875, 0.994140625, 0.99365234375, 0.990234375, 0.97509765625, 0.97509765625, 0.97265625, 0.96484375, 0.96337890625, 0.8505859375, 0.79296875, 0.78662109375, 0.6650390625, 0.603515625, 0.541015625, 0.51318359375, 0.5078125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.607421875, 0.591796875, 0.5849609375, 0.58056640625, 0.5791015625, 0.57861328125, 0.576171875, 0.57421875, 0.5712890625, 0.56884765625, 0.56494140625, 0.564453125, 0.5634765625, 0.55615234375, 0.5517578125, 0.54296875, 0.5419921875, 0.54052734375, 0.53564453125, 0.53515625, 0.53466796875, 0.52783203125, 0.52587890625, 0.52294921875, 0.52099609375, 0.5166015625, 0.513671875, 0.51318359375, 0.51318359375, 0.509765625, 0.509765625, 0.50634765625, 0.505859375, 0.50439453125, 0.50390625, 0.50390625, 0.50341796875, 0.5029296875, 0.5029296875, 0.5009765625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.87158203125, 0.86279296875, 0.76025390625, 0.72802734375, 0.70703125, 0.68505859375, 0.67919921875, 0.666015625, 0.666015625, 0.65869140625, 0.6572265625, 0.65478515625, 0.6513671875, 0.634765625, 0.62109375, 0.6181640625, 0.60693359375, 0.60546875, 0.57568359375, 0.57177734375, 0.5712890625, 0.5595703125, 0.55419921875, 0.5537109375, 0.5537109375, 0.55224609375, 0.5517578125, 0.533203125, 0.53076171875, 0.529296875, 0.5263671875, 0.52294921875, 0.52294921875, 0.5224609375, 0.51953125, 0.51171875, 0.51171875, 0.50830078125, 0.50048828125, 0.5]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.9990234375, 0.9990234375, 0.99853515625, 0.99853515625, 0.99853515625, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.99755859375, 0.99755859375, 0.9970703125, 0.9970703125, 0.9970703125, 0.99609375, 0.99609375, 0.99560546875, 0.99560546875, 0.99560546875, 0.99560546875, 0.99462890625, 0.99462890625, 0.99462890625, 0.9931640625, 0.99267578125, 0.99267578125, 0.99169921875, 0.99169921875, 0.9912109375, 0.99072265625, 0.98828125, 0.9833984375, 0.9814453125, 0.98095703125, 0.978515625, 0.9775390625, 0.97705078125, 0.96875, 0.96142578125, 0.9580078125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.86328125, 0.8388671875, 0.81787109375, 0.783203125, 0.7353515625, 0.705078125, 0.70263671875, 0.66845703125, 0.6455078125, 0.64111328125, 0.63720703125, 0.62841796875, 0.62060546875, 0.61669921875, 0.609375, 0.5986328125, 0.5859375, 0.578125, 0.57763671875, 0.57080078125, 0.56982421875, 0.5693359375, 0.56298828125, 0.5615234375, 0.55615234375, 0.5546875, 0.55322265625, 0.5517578125, 0.548828125, 0.54443359375, 0.53955078125, 0.53564453125, 0.5283203125, 0.5244140625, 0.5205078125, 0.517578125, 0.5126953125, 0.50537109375, 0.50390625, 0.5009765625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.99951171875, 0.9990234375, 0.9970703125, 0.9970703125, 0.99560546875, 0.9951171875, 0.99462890625, 0.98974609375, 0.98828125, 0.96435546875, 0.935546875, 0.93359375, 0.91162109375, 0.90576171875, 0.880859375, 0.85205078125, 0.849609375, 0.8486328125, 0.841796875, 0.8193359375, 0.76025390625, 0.7587890625, 0.75244140625, 0.748046875, 0.72216796875, 0.7138671875, 0.7109375, 0.69873046875, 0.68603515625, 0.66552734375, 0.6435546875, 0.630859375, 0.6279296875, 0.625, 0.580078125, 0.572265625, 0.54833984375, 0.541015625, 0.52001953125, 0.517578125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [1.0, 0.99951171875, 0.99853515625, 0.99462890625, 0.99365234375, 0.98583984375, 0.95068359375, 0.9267578125, 0.92626953125, 0.9189453125, 0.87060546875, 0.8623046875, 0.861328125, 0.83837890625, 0.830078125, 0.8037109375, 0.78759765625, 0.77783203125, 0.77587890625, 0.765625, 0.755859375, 0.69677734375, 0.66943359375, 0.658203125, 0.64892578125, 0.6376953125, 0.634765625, 0.62109375, 0.60791015625, 0.60546875, 0.599609375, 0.583984375, 0.57568359375, 0.56982421875, 0.548828125, 0.5439453125, 0.529296875, 0.525390625, 0.50341796875, 0.5]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.998046875, 0.99755859375, 0.99658203125, 0.99658203125, 0.99609375, 0.99560546875, 0.99560546875, 0.9951171875, 0.99462890625, 0.994140625, 0.994140625, 0.9931640625, 0.99169921875, 0.99169921875, 0.99072265625, 0.990234375, 0.98779296875, 0.9873046875, 0.98681640625, 0.98681640625, 0.986328125, 0.98193359375, 0.978515625, 0.97802734375, 0.97607421875, 0.97607421875, 0.9755859375, 0.9736328125, 0.97216796875, 0.97119140625, 0.96484375, 0.9580078125, 0.93896484375, 0.9375, 0.935546875, 0.88232421875, 0.86083984375, 0.84326171875, 0.80859375, 0.7197265625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [1.0, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.9990234375, 0.9990234375, 0.9990234375, 0.9990234375, 0.99853515625, 0.99853515625, 0.99853515625, 0.99853515625, 0.99853515625, 0.99853515625, 0.99853515625, 0.998046875, 0.998046875, 0.998046875, 0.998046875, 0.99755859375, 0.99755859375, 0.99755859375, 0.9970703125, 0.99609375, 0.990234375, 0.9833984375, 0.97802734375, 0.7392578125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.9990234375, 0.99755859375, 0.99609375, 0.99609375, 0.99609375, 0.99560546875, 0.99560546875, 0.99462890625, 0.99462890625, 0.99462890625, 0.99462890625, 0.9931640625, 0.9931640625, 0.9921875, 0.990234375, 0.98974609375, 0.9892578125, 0.98876953125, 0.98876953125, 0.98779296875, 0.986328125, 0.98583984375, 0.9833984375, 0.9833984375, 0.98291015625, 0.982421875, 0.98193359375, 0.9814453125, 0.9814453125, 0.98046875, 0.97998046875, 0.97998046875, 0.9658203125, 0.96484375, 0.9541015625, 0.9443359375, 0.93701171875, 0.9296875, 0.90869140625, 0.5166015625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [1.0, 0.99951171875, 0.99951171875, 0.99951171875, 0.9990234375, 0.9990234375, 0.99853515625, 0.99853515625, 0.99853515625, 0.998046875, 0.998046875, 0.998046875, 0.99755859375, 0.9970703125, 0.9970703125, 0.99658203125, 0.99560546875, 0.9951171875, 0.99462890625, 0.99462890625, 0.994140625, 0.994140625, 0.994140625, 0.99365234375, 0.9931640625, 0.9931640625, 0.99267578125, 0.9921875, 0.9921875, 0.99169921875, 0.9892578125, 0.98828125, 0.9853515625, 0.98486328125, 0.98193359375, 0.9736328125, 0.96875, 0.95703125, 0.93408203125, 0.80810546875]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.99755859375, 0.9970703125, 0.99609375, 0.99462890625, 0.994140625, 0.99365234375, 0.99365234375, 0.99267578125, 0.99072265625, 0.990234375, 0.98974609375, 0.9892578125, 0.98876953125, 0.98779296875, 0.9873046875, 0.986328125, 0.98486328125, 0.98486328125, 0.98486328125, 0.982421875, 0.98193359375, 0.98193359375, 0.9814453125, 0.9814453125, 0.9775390625, 0.9775390625, 0.97607421875, 0.9736328125, 0.970703125, 0.97021484375, 0.96728515625, 0.96630859375, 0.9638671875, 0.96142578125, 0.95703125, 0.95166015625, 0.888671875, 0.87841796875, 0.791015625, 0.68896484375]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.9970703125, 0.9951171875, 0.994140625, 0.99365234375, 0.98779296875, 0.98779296875, 0.98291015625, 0.97900390625, 0.97216796875, 0.97119140625, 0.9697265625, 0.96533203125, 0.95703125, 0.95654296875, 0.9521484375, 0.94287109375, 0.93701171875, 0.935546875, 0.93505859375, 0.91064453125, 0.90478515625, 0.88623046875, 0.8740234375, 0.86669921875, 0.8115234375, 0.78955078125, 0.75732421875, 0.748046875, 0.7099609375, 0.64453125, 0.63427734375, 0.60888671875, 0.6083984375, 0.60107421875, 0.57177734375, 0.54736328125, 0.53857421875, 0.5244140625, 0.52392578125, 0.5087890625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.99755859375, 0.9970703125, 0.99658203125, 0.99560546875, 0.99560546875, 0.99462890625, 0.99462890625, 0.9931640625, 0.99267578125, 0.99072265625, 0.9892578125, 0.98876953125, 0.98828125, 0.98291015625, 0.9814453125, 0.97509765625, 0.9736328125, 0.962890625, 0.96142578125, 0.95068359375, 0.94677734375, 0.94189453125, 0.93115234375, 0.92529296875, 0.896484375, 0.8896484375, 0.8671875, 0.8564453125, 0.85107421875, 0.84912109375, 0.80712890625, 0.78955078125, 0.77978515625, 0.76904296875, 0.7333984375, 0.66845703125, 0.64306640625, 0.5537109375, 0.5234375, 0.5048828125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.8994140625, 0.8681640625, 0.82080078125, 0.7666015625, 0.74462890625, 0.732421875, 0.73095703125, 0.72607421875, 0.712890625, 0.703125, 0.69775390625, 0.67529296875, 0.66748046875, 0.646484375, 0.6435546875, 0.6357421875, 0.6337890625, 0.6123046875, 0.60205078125, 0.5947265625, 0.58642578125, 0.58056640625, 0.5732421875, 0.56298828125, 0.55712890625, 0.55615234375, 0.54541015625, 0.54052734375, 0.533203125, 0.529296875, 0.5244140625, 0.5224609375, 0.51904296875, 0.51904296875, 0.51416015625, 0.5107421875, 0.509765625, 0.509765625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.85546875, 0.80859375, 0.79736328125, 0.7529296875, 0.75146484375, 0.73876953125, 0.73681640625, 0.697265625, 0.67578125, 0.64990234375, 0.63623046875, 0.6220703125, 0.61572265625, 0.59619140625, 0.58544921875, 0.58203125, 0.57373046875, 0.552734375, 0.5419921875, 0.50537109375, 0.50244140625, 0.50048828125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.89306640625, 0.880859375, 0.86083984375, 0.85107421875, 0.83251953125, 0.82958984375, 0.81201171875, 0.810546875, 0.78173828125, 0.78076171875, 0.77734375, 0.76708984375, 0.73046875, 0.72607421875, 0.71337890625, 0.70068359375, 0.67724609375, 0.640625, 0.63232421875, 0.619140625, 0.5888671875, 0.57666015625, 0.5673828125, 0.56396484375, 0.55419921875, 0.513671875, 0.513671875]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.9287109375, 0.9169921875, 0.8369140625, 0.796875, 0.7607421875, 0.689453125, 0.6298828125, 0.56689453125, 0.533203125, 0.51513671875]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.94580078125, 0.94140625, 0.9404296875, 0.916015625, 0.8916015625, 0.890625, 0.88720703125, 0.86669921875, 0.837890625, 0.81494140625, 0.8037109375, 0.79248046875, 0.7919921875, 0.7646484375, 0.6962890625, 0.68896484375, 0.63525390625, 0.62841796875, 0.583984375, 0.55859375, 0.52197265625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.79248046875, 0.78076171875, 0.658203125, 0.63427734375, 0.62353515625, 0.60791015625, 0.59033203125, 0.58447265625, 0.57666015625, 0.572265625, 0.5693359375, 0.56884765625, 0.556640625, 0.55517578125, 0.53857421875, 0.53662109375, 0.52783203125, 0.52685546875, 0.52197265625, 0.513671875, 0.51220703125, 0.5048828125, 0.50390625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.9404296875, 0.91845703125, 0.9140625, 0.8701171875, 0.85546875, 0.82080078125, 0.81640625, 0.80517578125, 0.80126953125, 0.80126953125, 0.75390625, 0.751953125, 0.7314453125, 0.73046875, 0.72265625, 0.7099609375, 0.70849609375, 0.70654296875, 0.69140625, 0.6875, 0.68701171875, 0.65576171875, 0.64599609375, 0.64501953125, 0.63427734375, 0.62255859375, 0.6181640625, 0.61083984375, 0.6103515625, 0.60205078125, 0.59228515625, 0.5439453125, 0.52490234375, 0.5205078125, 0.52001953125, 0.51806640625, 0.5029296875]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.892578125, 0.8740234375, 0.8515625, 0.84521484375, 0.833984375, 0.8291015625, 0.82177734375, 0.81494140625, 0.814453125, 0.81396484375, 0.79296875, 0.7734375, 0.76953125, 0.75439453125, 0.71240234375, 0.70361328125, 0.6669921875, 0.634765625, 0.5927734375, 0.5927734375, 0.5810546875, 0.5751953125, 0.57421875, 0.56884765625, 0.56787109375, 0.552734375, 0.5390625, 0.53564453125, 0.53271484375, 0.53125, 0.52001953125, 0.51611328125, 0.50244140625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.716796875, 0.64453125, 0.61572265625, 0.6083984375, 0.60693359375, 0.5908203125, 0.58837890625, 0.57763671875, 0.57568359375, 0.5751953125, 0.5732421875, 0.57177734375, 0.5654296875, 0.56494140625, 0.5546875, 0.5400390625, 0.53466796875, 0.5224609375, 0.5146484375, 0.51416015625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.9423828125, 0.849609375, 0.7236328125, 0.6474609375, 0.5498046875, 0.5439453125, 0.5107421875]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.90673828125, 0.8837890625, 0.86767578125, 0.853515625, 0.83740234375, 0.83544921875, 0.82666015625, 0.82421875, 0.8232421875, 0.8212890625, 0.81201171875, 0.802734375, 0.79736328125, 0.796875, 0.7783203125, 0.771484375, 0.76806640625, 0.76708984375, 0.7666015625, 0.76416015625, 0.76171875, 0.75927734375, 0.7568359375, 0.7529296875, 0.751953125, 0.73486328125, 0.72265625, 0.7216796875, 0.7177734375, 0.7099609375, 0.701171875, 0.681640625, 0.6748046875, 0.66796875, 0.63623046875, 0.63232421875, 0.62255859375, 0.6171875, 0.61376953125, 0.51220703125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.9443359375, 0.90087890625, 0.84130859375, 0.83740234375, 0.81201171875, 0.7939453125, 0.7919921875, 0.79150390625, 0.7587890625, 0.75732421875, 0.74560546875, 0.69140625, 0.626953125, 0.5849609375, 0.5478515625, 0.53466796875, 0.5166015625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.810546875, 0.74951171875, 0.69921875, 0.6943359375, 0.66552734375, 0.64013671875, 0.63671875, 0.5966796875, 0.59228515625, 0.5908203125, 0.5732421875, 0.57080078125, 0.5693359375, 0.5693359375, 0.5634765625, 0.56005859375, 0.55908203125, 0.55322265625, 0.546875, 0.53857421875, 0.5380859375, 0.5302734375, 0.52197265625, 0.5166015625, 0.50927734375, 0.5068359375]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.908203125, 0.82275390625, 0.8154296875, 0.78515625, 0.7822265625, 0.76416015625, 0.7548828125, 0.73876953125, 0.681640625, 0.666015625, 0.6591796875, 0.65869140625, 0.5927734375, 0.5791015625, 0.57763671875, 0.5625, 0.55224609375, 0.53466796875, 0.5302734375, 0.521484375, 0.521484375, 0.51513671875]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.96240234375, 0.93212890625, 0.8017578125, 0.78271484375, 0.75, 0.72607421875, 0.72412109375, 0.720703125, 0.716796875, 0.71240234375, 0.69189453125, 0.68603515625, 0.6796875, 0.67822265625, 0.66650390625, 0.6650390625, 0.65869140625, 0.64892578125, 0.62841796875, 0.60302734375, 0.59228515625, 0.58642578125, 0.564453125, 0.560546875, 0.5576171875, 0.55224609375, 0.54736328125, 0.53857421875, 0.53466796875, 0.5283203125, 0.52734375]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.98486328125, 0.9580078125, 0.95703125, 0.93408203125, 0.9208984375, 0.91162109375, 0.9052734375, 0.89453125, 0.8935546875, 0.87744140625, 0.87548828125, 0.84423828125, 0.82373046875, 0.80322265625, 0.7998046875, 0.75390625, 0.7509765625, 0.73681640625, 0.69775390625, 0.67333984375, 0.65087890625, 0.6435546875, 0.57421875]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.994140625, 0.98193359375, 0.98046875, 0.94970703125, 0.94921875, 0.9306640625, 0.921875, 0.89111328125, 0.890625, 0.8583984375, 0.8271484375, 0.71435546875]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.99560546875, 0.99169921875, 0.98974609375, 0.986328125, 0.9833984375, 0.9609375, 0.94677734375, 0.93310546875, 0.91796875, 0.8759765625, 0.6923828125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.99755859375, 0.93798828125, 0.908203125, 0.89892578125, 0.79345703125, 0.7705078125, 0.69775390625, 0.67041015625, 0.65673828125, 0.6376953125, 0.63232421875, 0.564453125, 0.53857421875, 0.52392578125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.9990234375, 0.99072265625, 0.974609375, 0.970703125, 0.96826171875, 0.96826171875, 0.96484375, 0.96435546875, 0.95751953125, 0.95263671875, 0.939453125, 0.927734375, 0.92431640625, 0.92236328125, 0.91552734375, 0.91357421875, 0.89404296875, 0.88720703125, 0.88427734375, 0.84716796875, 0.82568359375, 0.8251953125, 0.82080078125, 0.77587890625, 0.72119140625, 0.64794921875, 0.62890625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.99951171875, 0.99951171875, 0.99658203125, 0.99560546875, 0.9951171875, 0.9951171875, 0.990234375, 0.990234375, 0.9814453125, 0.98095703125, 0.9794921875, 0.97509765625, 0.97412109375, 0.96337890625, 0.95849609375, 0.95751953125, 0.953125, 0.94921875, 0.94873046875, 0.9384765625, 0.92431640625, 0.92138671875, 0.91796875, 0.90869140625, 0.9033203125, 0.89208984375, 0.8857421875, 0.81005859375, 0.79736328125, 0.78173828125, 0.76171875, 0.75146484375, 0.71484375, 0.70556640625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.8154296875, 0.783203125, 0.68701171875, 0.6416015625, 0.60546875, 0.6025390625, 0.5986328125, 0.58740234375, 0.580078125, 0.57763671875, 0.57470703125, 0.57080078125, 0.56884765625, 0.5673828125, 0.544921875, 0.54443359375, 0.54345703125, 0.54248046875, 0.53955078125, 0.5283203125, 0.5107421875]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.9951171875, 0.994140625, 0.98974609375, 0.97998046875, 0.9697265625, 0.96923828125, 0.96484375, 0.96337890625, 0.95556640625, 0.955078125, 0.95166015625, 0.93017578125, 0.9267578125, 0.9091796875, 0.84765625, 0.84326171875, 0.830078125, 0.80859375, 0.72607421875, 0.6533203125, 0.65283203125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.99951171875, 0.99853515625, 0.9970703125, 0.99462890625, 0.9921875, 0.99072265625, 0.99072265625, 0.9892578125, 0.984375, 0.98388671875, 0.98388671875, 0.98291015625, 0.98193359375, 0.9814453125, 0.97705078125, 0.97509765625, 0.9716796875, 0.96875, 0.96728515625, 0.9609375, 0.9521484375, 0.93359375, 0.90087890625, 0.8974609375, 0.890625, 0.88330078125, 0.8486328125, 0.84033203125, 0.83544921875, 0.80859375]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.947265625, 0.9287109375, 0.85595703125, 0.826171875, 0.814453125, 0.7568359375, 0.75146484375, 0.708984375, 0.69287109375, 0.6689453125, 0.603515625, 0.6005859375, 0.5986328125, 0.59423828125, 0.5888671875, 0.587890625, 0.58544921875, 0.57275390625, 0.56787109375, 0.56005859375, 0.548828125, 0.5400390625, 0.5390625, 0.529296875, 0.5087890625, 0.50634765625, 0.5009765625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.9990234375, 0.96533203125, 0.8388671875, 0.74169921875, 0.7099609375, 0.66162109375, 0.63916015625, 0.55078125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.99951171875, 0.9951171875, 0.9951171875, 0.9921875, 0.99169921875, 0.99169921875, 0.98974609375, 0.98876953125, 0.98583984375, 0.97607421875, 0.97119140625, 0.97021484375, 0.96728515625, 0.966796875, 0.95458984375, 0.93994140625, 0.92578125, 0.90576171875, 0.884765625, 0.86328125, 0.8115234375, 0.8056640625, 0.7705078125, 0.7021484375, 0.55810546875, 0.548828125, 0.515625]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.97265625, 0.953125, 0.9521484375, 0.94921875, 0.8974609375, 0.85546875, 0.85546875, 0.7255859375, 0.6875, 0.63037109375, 0.6142578125, 0.60595703125, 0.59814453125, 0.53271484375]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.6484375, 0.6328125, 0.58056640625, 0.5419921875, 0.53515625, 0.5205078125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.712890625, 0.6923828125, 0.65234375, 0.650390625, 0.6142578125, 0.6083984375, 0.58935546875, 0.58642578125, 0.583984375, 0.57470703125, 0.56982421875, 0.56005859375, 0.55419921875, 0.5498046875, 0.54736328125, 0.546875, 0.53564453125, 0.5322265625, 0.52294921875, 0.521484375, 0.52099609375, 0.52099609375, 0.51904296875, 0.51513671875, 0.51025390625, 0.5087890625, 0.5048828125, 0.5048828125, 0.5029296875, 0.5029296875, 0.50048828125]\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Saving: client_2_class_basketball_cluster_0.png | Class label: basketball, Cluster size: 40\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 📦 fit() called on client.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 1] evaluate() called.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m  [CLient 0] is Converged and start constructing the needed Clusters\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m [Client 0] ThesisKMeansClient created successfully\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m  [CLient 0] is Proceeding for Training CAVs and computing TCAV scores...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m  [CLient 0] Picking up the nearest 40 instaces to the clusters' centriods...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m 229 unique discovery images for class 2\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Class 2 Cluster 14: size=17, unique_imgs=14, mean_clip_score=0.602, keep=True\u001b[32m [repeated 82x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Class 2 Cluster 13: size=5, unique_imgs=4, mean_clip_score=0.677, keep=False\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Accepted cluster: basketball | CLIP scores: [0.99853515625, 0.99853515625, 0.998046875, 0.9970703125, 0.9970703125, 0.9970703125, 0.99560546875, 0.9921875, 0.99169921875, 0.98828125, 0.98828125, 0.986328125, 0.98388671875, 0.9814453125, 0.9814453125, 0.9814453125, 0.97705078125, 0.97705078125, 0.97119140625, 0.95751953125, 0.95751953125, 0.9541015625, 0.951171875, 0.88330078125, 0.8818359375, 0.8720703125, 0.86328125, 0.861328125, 0.84912109375, 0.76953125, 0.75830078125, 0.71337890625, 0.70849609375, 0.6865234375, 0.66650390625, 0.62939453125, 0.58544921875, 0.57763671875, 0.56884765625, 0.505859375]\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Accepted cluster: mountain bike | CLIP scores: [0.89794921875, 0.87451171875, 0.87451171875, 0.7392578125, 0.71923828125, 0.6982421875, 0.68701171875, 0.67333984375, 0.669921875, 0.623046875, 0.5966796875, 0.55712890625, 0.5546875, 0.5458984375, 0.544921875, 0.53857421875, 0.52880859375, 0.52294921875, 0.52099609375, 0.52001953125, 0.51953125, 0.5146484375, 0.51025390625, 0.5078125, 0.5048828125]\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Accepted cluster: moving van | CLIP scores: [0.9990234375, 0.7490234375, 0.71923828125, 0.66552734375, 0.6298828125, 0.62548828125, 0.59375, 0.55712890625, 0.548828125, 0.5458984375, 0.5439453125, 0.53173828125, 0.5078125, 0.505859375, 0.50341796875, 0.5029296875, 0.50244140625]\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Saving: client_2_class_basketball_cluster_3.png | Class label: basketball, Cluster size: 40\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Saving: client_2_class_basketball_cluster_6.png | Class label: basketball, Cluster size: 40\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Saving: client_1_class_basketball_cluster_7.png | Class label: basketball, Cluster size: 40\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Saving: client_2_class_basketball_cluster_12.png | Class label: basketball, Cluster size: 40\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Saving: client_0_class_basketball_cluster_14.png | Class label: basketball, Cluster size: 40\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Saving: client_2_class_mountain bike_cluster_0.png | Class label: mountain bike, Cluster size: 38\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Saving: client_1_class_basketball_cluster_14.png | Class label: basketball, Cluster size: 40\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Saving: client_0_class_mountain bike_cluster_2.png | Class label: mountain bike, Cluster size: 31\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Saving: client_1_class_mountain bike_cluster_3.png | Class label: mountain bike, Cluster size: 9\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Saving: client_1_class_mountain bike_cluster_6.png | Class label: mountain bike, Cluster size: 40\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Saving: client_0_class_mountain bike_cluster_9.png | Class label: mountain bike, Cluster size: 12\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Saving: client_0_class_mountain bike_cluster_12.png | Class label: mountain bike, Cluster size: 23\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Saving: client_2_class_moving van_cluster_0.png | Class label: moving van, Cluster size: 23\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m Saving: client_0_class_mountain bike_cluster_14.png | Class label: mountain bike, Cluster size: 25\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Saving: client_2_class_moving van_cluster_3.png | Class label: moving van, Cluster size: 14\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Saving: client_1_class_mountain bike_cluster_14.png | Class label: mountain bike, Cluster size: 24\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Saving: client_1_class_moving van_cluster_3.png | Class label: moving van, Cluster size: 10\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Saving: client_1_class_moving van_cluster_6.png | Class label: moving van, Cluster size: 8\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Saving: client_1_class_moving van_cluster_9.png | Class label: moving van, Cluster size: 18\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Saving: client_1_class_moving van_cluster_13.png | Class label: moving van, Cluster size: 9\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   warn(\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m Using cache found in /gpfs/helios/home/mahmouds/.cache/torch/hub/facebookresearch_dinov2_main\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ipykernel_2478198/2306875635.py:480: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ipykernel_2478198/2306875635.py:480: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   warn(\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   warn(\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ipykernel_2478198/2306875635.py:480: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ipykernel_2478198/2306875635.py:480: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /tmp/ipykernel_2478198/2306875635.py:480: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m all the related CAV of Class basketball was successfully generated : \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m  {('basketball', 0): array([-0.04763583, -0.0035804 ,  0.02143745, ..., -0.00976052,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.03818613, -0.02006265]), ('basketball', 1): array([ 0.01392935, -0.01990792,  0.00575332, ..., -0.00595984,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.09171634, -0.01339617]), ('basketball', 2): array([-0.0585596 , -0.00152944,  0.01039192, ..., -0.02231009,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.0118166 , -0.01537933]), ('basketball', 3): array([ 5.56098225e-02, -2.07386354e-05,  4.98173763e-02, ...,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         8.68821087e-03,  6.67052556e-02, -5.51714741e-03]), ('basketball', 4): array([ 0.0192755 , -0.00903961, -0.03000609, ...,  0.01795829,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.0555156 , -0.01465434]), ('basketball', 5): array([ 0.05612083,  0.0109315 , -0.00047939, ..., -0.00163069,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.04856647, -0.00843549]), ('basketball', 6): array([-0.02803687, -0.01669495, -0.02148768, ..., -0.00251372,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.00742306, -0.00767064]), ('basketball', 7): array([-0.05222454, -0.01256952, -0.00633325, ...,  0.03645126,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.048756  ,  0.00598852]), ('basketball', 8): array([-0.01680013, -0.02394643, -0.02570475, ...,  0.00656111,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.01724184, -0.038217  ]), ('basketball', 9): array([-0.03621612, -0.02074228, -0.02671759, ..., -0.00817757,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.01258067, -0.01000656]), ('basketball', 10): array([-0.03625664, -0.01607249, -0.01805783, ..., -0.01065318,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.00212144,  0.0099383 ]), ('basketball', 11): array([-0.00491947, -0.00400262,  0.04660265, ...,  0.01103257,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.03497621,  0.00586473]), ('basketball', 12): array([ 0.01563469, -0.0024982 ,  0.00605743, ...,  0.00030059,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.01352169, -0.02788917]), ('basketball', 13): array([ 0.01207602,  0.02355546,  0.0080077 , ..., -0.00742534,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.02901301, -0.00934323]), ('basketball', 14): array([ 0.0498438 , -0.00697053, -0.00266618, ...,  0.04377719,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.00327671,  0.02020404])} \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m Saving: client_1_class_moving van_cluster_14.png | Class label: moving van, Cluster size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m  {('basketball', 0): array([ 0.02142853, -0.00327417, -0.01680999, ..., -0.00220244,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.0140937 , -0.007679  ]), ('basketball', 3): array([ 0.0320017 ,  0.00906123,  0.0109805 , ...,  0.00413518,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.00142039, -0.00872161]), ('basketball', 7): array([-0.0250019 ,  0.00427641, -0.0255328 , ...,  0.02979825,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.00536631, -0.00207334]), ('basketball', 9): array([-0.0401948 , -0.02654492, -0.03143565, ...,  0.0022854 ,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.04514221, -0.01299696]), ('basketball', 10): array([ 0.0139869 , -0.0102409 , -0.01921236, ...,  0.01593905,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.03841658,  0.03530194])} \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m  {('basketball', 0): array([-0.03739622, -0.00411158, -0.00067806, ..., -0.00193778,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.07146897, -0.0121714 ]), ('basketball', 4): array([ 0.03771825, -0.0046272 , -0.0371666 , ...,  0.00357401,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.01192192,  0.00146861])} \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m all the related CAV of Class basketball was successfully generated : \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.03402389, -0.00627204]), ('basketball', 10): array([ 0.00999777,  0.00144792, -0.00801362, ..., -0.00576945,\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.00650519,  0.01022033]), ('basketball', 11): array([-0.00717181, -0.00758908,  0.0508886 , ...,  0.01578842,\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.03776461, -0.00700463]), ('basketball', 14): array([ 0.0350432 ,  0.00717682, -0.02400191, ...,  0.03859104,\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.05423841,  0.02977708]), ('basketball', 9): array([-0.04001155, -0.02018358, -0.03707447, ..., -0.00060582,\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.0286081 , -0.00880425]), ('basketball', 2): array([-0.02357098,  0.02425544, -0.01580898, ..., -0.00662734,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.02259594, -0.0168617 ]), ('basketball', 1): array([-0.00400034, -0.00556237, -0.00783795, ..., -0.00121978,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m all the related CAV of Class mountain bike was successfully generated : \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m  {('basketball', 0): array([-0.04763583, -0.0035804 ,  0.02143745, ..., -0.00976052,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.0118166 , -0.01537933]), ('basketball', 3): array([ 5.56098225e-02, -2.07386354e-05,  4.98173763e-02, ...,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.0555156 , -0.01465434]), ('basketball', 5): array([ 0.05612083,  0.0109315 , -0.00047939, ..., -0.00163069,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.048756  ,  0.00598852]), ('basketball', 8): array([-0.01680013, -0.02394643, -0.02570475, ...,  0.00656111,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.01724184, -0.038217  ]), ('basketball', 9): array([-0.03621612, -0.02074228, -0.02671759, ..., -0.00817757,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.00212144,  0.0099383 ]), ('basketball', 11): array([-0.00491947, -0.00400262,  0.04660265, ...,  0.01103257,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.00327671,  0.02020404]), ('mountain bike', 0): array([-0.01669582, -0.02397588, -0.03440079, ..., -0.00290634,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.01205784, -0.01058121]), ('mountain bike', 1): array([ 0.0177087 ,  0.00254116, -0.01621123, ...,  0.00660478,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.02164989,  0.03091502]), ('mountain bike', 2): array([-0.00191277,  0.02963227, -0.03117782, ...,  0.02317135,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.03785298, -0.0133521 ]), ('mountain bike', 3): array([ 0.02439257,  0.00477361, -0.01595669, ..., -0.00899765,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.05424249,  0.00424259]), ('mountain bike', 4): array([-0.02735715,  0.03542083, -0.03873714, ...,  0.01742296,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.08781146, -0.00657289]), ('mountain bike', 5): array([-0.05135221,  0.04108156, -0.0460167 , ..., -0.0060976 ,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.01692851, -0.00546152]), ('mountain bike', 6): array([-0.00708224, -0.04196484,  0.04426881, ..., -0.00510824,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.0223307 , -0.01236561]), ('mountain bike', 7): array([-0.01411394,  0.06444711,  0.01384266, ...,  0.00790813,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.01954236,  0.02401088]), ('mountain bike', 8): array([-0.02610718,  0.01354064, -0.00560134, ..., -0.00462496,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.06280772,  0.00208303]), ('mountain bike', 9): array([-0.02140005, -0.00554658,  0.04327178, ..., -0.01191847,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.02956265, -0.00364737]), ('mountain bike', 10): array([-0.01343261,  0.00362274, -0.02805306, ..., -0.00337406,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.01290168, -0.00319328]), ('mountain bike', 11): array([-0.03665098,  0.00858274, -0.01174683, ..., -0.00394771,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.00419625, -0.00652037]), ('mountain bike', 12): array([ 0.00349958,  0.06194529,  0.05310954, ...,  0.00213406,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.01929614, -0.00194312]), ('mountain bike', 13): array([-0.01950601,  0.05932692,  0.01994858, ...,  0.03836239,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.04179808,  0.02374472]), ('mountain bike', 14): array([ 0.00689253,  0.0329761 ,  0.11266738, ..., -0.01566095,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.01001353, -0.00537291])} \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.03818613, -0.02006265]), ('basketball', 1): array([ 0.01392935, -0.01990792,  0.00575332, ..., -0.00595984,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.09171634, -0.01339617]), ('basketball', 2): array([-0.0585596 , -0.00152944,  0.01039192, ..., -0.02231009,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.02901301, -0.00934323]), ('basketball', 14): array([ 0.0498438 , -0.00697053, -0.00266618, ...,  0.04377719,\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.01258067, -0.01000656]), ('basketball', 10): array([-0.03625664, -0.01607249, -0.01805783, ..., -0.01065318,\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m  {('basketball', 0): array([ 0.02142853, -0.00327417, -0.01680999, ..., -0.00220244,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.0140937 , -0.007679  ]), ('basketball', 3): array([ 0.0320017 ,  0.00906123,  0.0109805 , ...,  0.00413518,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.05636271, -0.01758508]), ('basketball', 4): array([ 0.03570607, -0.00136196, -0.02426181, ..., -0.01331987,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.00142039, -0.00872161]), ('basketball', 7): array([-0.0250019 ,  0.00427641, -0.0255328 , ...,  0.02979825,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.00536631, -0.00207334]), ('basketball', 9): array([-0.0401948 , -0.02654492, -0.03143565, ...,  0.0022854 ,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.04514221, -0.01299696]), ('basketball', 10): array([ 0.0139869 , -0.0102409 , -0.01921236, ...,  0.01593905,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.04182235, -0.00020213]), ('basketball', 12): array([-0.03272835,  0.00374985,  0.0029387 , ..., -0.01115863,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.01124012, -0.00124383]), ('basketball', 14): array([ 0.10836326, -0.00903333, -0.02622566, ...,  0.04334626,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.06810667, -0.00150155]), ('mountain bike', 5): array([ 0.00693134,  0.01393553, -0.01967798, ...,  0.0122983 ,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.0284926 , -0.00576641]), ('mountain bike', 7): array([-0.00764953,  0.05922888,  0.04825101, ..., -0.0134859 ,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.00844988,  0.00553857]), ('mountain bike', 14): array([-0.01614219,  0.0817646 ,  0.03982547, ..., -0.00158651,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.07504241,  0.00067936])} \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m  {('basketball', 0): array([-0.03739622, -0.00411158, -0.00067806, ..., -0.00193778,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.07146897, -0.0121714 ]), ('basketball', 4): array([ 0.03771825, -0.0046272 , -0.0371666 , ...,  0.00357401,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        0.00921352])} \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m all the related CAV of Class mountain bike was successfully generated : \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.0286081 , -0.00880425]), ('basketball', 2): array([-0.02357098,  0.02425544, -0.01580898, ..., -0.00662734,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.02259594, -0.0168617 ]), ('basketball', 1): array([-0.00400034, -0.00556237, -0.00783795, ..., -0.00121978,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.06543341, -0.00353427]), ('mountain bike', 13): array([-0.01059264,  0.05999139,  0.03189706, ...,  0.02411757,\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         1.92899145e-02, -2.13982739e-02,  1.86951125e-02]), ('mountain bike', 8): array([ 0.00717758, -0.0348178 ,  0.03909295, ..., -0.02023421,\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.01274052, -0.00467372]), ('mountain bike', 12): array([ 0.00214215,  0.01569178,  0.00769271, ..., -0.00740189,\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.03776461, -0.00700463]), ('basketball', 14): array([ 0.0350432 ,  0.00717682, -0.02400191, ...,  0.03859104,\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.05423841,  0.02977708]), ('basketball', 9): array([-0.04001155, -0.02018358, -0.03707447, ..., -0.00060582,\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m all the related CAV of Class moving van was successfully generated : \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m  {('basketball', 0): array([-0.04763583, -0.0035804 ,  0.02143745, ..., -0.00976052,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.0118166 , -0.01537933]), ('basketball', 3): array([ 5.56098225e-02, -2.07386354e-05,  4.98173763e-02, ...,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.0555156 , -0.01465434]), ('basketball', 5): array([ 0.05612083,  0.0109315 , -0.00047939, ..., -0.00163069,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.048756  ,  0.00598852]), ('basketball', 8): array([-0.01680013, -0.02394643, -0.02570475, ...,  0.00656111,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.01724184, -0.038217  ]), ('basketball', 9): array([-0.03621612, -0.02074228, -0.02671759, ..., -0.00817757,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.00212144,  0.0099383 ]), ('basketball', 11): array([-0.00491947, -0.00400262,  0.04660265, ...,  0.01103257,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.03785298, -0.0133521 ]), ('mountain bike', 3): array([ 0.02439257,  0.00477361, -0.01595669, ..., -0.00899765,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.08781146, -0.00657289]), ('mountain bike', 5): array([-0.05135221,  0.04108156, -0.0460167 , ..., -0.0060976 ,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.0223307 , -0.01236561]), ('mountain bike', 7): array([-0.01411394,  0.06444711,  0.01384266, ...,  0.00790813,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.01001353, -0.00537291]), ('moving van', 0): array([-0.08342819, -0.00742679,  0.0226107 , ..., -0.00252874,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.00145849, -0.0184132 ]), ('moving van', 1): array([ 0.03008455,  0.01022548,  0.02755746, ..., -0.00089898,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.08305702,  0.01349868]), ('moving van', 2): array([ 0.0182238 ,  0.0078625 , -0.01545583, ...,  0.01884211,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.05416853, -0.00667949]), ('moving van', 3): array([-0.00728975, -0.02294362, -0.00187407, ...,  0.00273733,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.0115832 , -0.00244084]), ('moving van', 4): array([ 0.03006181,  0.00757194, -0.00158405, ..., -0.00558713,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.03635131, -0.00691391]), ('moving van', 5): array([ 0.07829414, -0.00380799, -0.01353009, ...,  0.00624176,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.04962278,  0.00177377]), ('moving van', 6): array([ 0.04115812,  0.006485  ,  0.01500985, ..., -0.00179679,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.03006662,  0.01549734]), ('moving van', 7): array([ 0.02230256, -0.01158003, -0.0401704 , ..., -0.01567892,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.04104328,  0.0063068 ]), ('moving van', 8): array([ 0.0513356 , -0.0082179 ,  0.00328746, ...,  0.0032857 ,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.02151113, -0.00022897]), ('moving van', 9): array([-0.01880686, -0.01273773,  0.02847171, ...,  0.01261572,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.03739017, -0.00690071]), ('moving van', 10): array([ 0.04790298, -0.01012488, -0.02637009, ...,  0.00807301,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.00027416, -0.01641891]), ('moving van', 11): array([-0.0287902 , -0.01455721, -0.03009648, ..., -0.00820395,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.00624308,  0.03404118]), ('moving van', 12): array([ 0.00489579, -0.01686774,  0.00299125, ..., -0.00552792,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.02090499,  0.03642063]), ('moving van', 13): array([-0.0179755 , -0.00998257, -0.00644144, ...,  0.00205863,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.03486757,  0.00479834]), ('moving van', 14): array([-0.02546394,  0.0064034 , -0.02866636, ...,  0.00218103,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.03803692, -0.00112663])} \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.03818613, -0.02006265]), ('basketball', 1): array([ 0.01392935, -0.01990792,  0.00575332, ..., -0.00595984,\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.09171634, -0.01339617]), ('basketball', 2): array([-0.0585596 , -0.00152944,  0.01039192, ..., -0.02231009,\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.02936756, -0.01130002]), ('mountain bike', 14): array([0.0094058 , 0.07133331, 0.04146965, ..., 0.00535488, 0.01693267,\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.01929614, -0.00194312]), ('mountain bike', 13): array([-0.01950601,  0.05932692,  0.01994858, ...,  0.03836239,\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.04179808,  0.02374472]), ('mountain bike', 14): array([ 0.00689253,  0.0329761 ,  0.11266738, ..., -0.01566095,\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.00419625, -0.00652037]), ('mountain bike', 12): array([ 0.00349958,  0.06194529,  0.05310954, ...,  0.00213406,\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m         0.02901301, -0.00934323]), ('basketball', 14): array([ 0.0498438 , -0.00697053, -0.00266618, ...,  0.04377719,\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m        -0.01258067, -0.01000656]), ('basketball', 10): array([-0.03625664, -0.01607249, -0.01805783, ..., -0.01065318,\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m  {('basketball', 0): array([ 0.02142853, -0.00327417, -0.01680999, ..., -0.00220244,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.0140937 , -0.007679  ]), ('basketball', 3): array([ 0.0320017 ,  0.00906123,  0.0109805 , ...,  0.00413518,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.00142039, -0.00872161]), ('basketball', 7): array([-0.0250019 ,  0.00427641, -0.0255328 , ...,  0.02979825,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.00536631, -0.00207334]), ('basketball', 9): array([-0.0401948 , -0.02654492, -0.03143565, ...,  0.0022854 ,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.04514221, -0.01299696]), ('basketball', 10): array([ 0.0139869 , -0.0102409 , -0.01921236, ...,  0.01593905,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.03841658,  0.03530194]), ('mountain bike', 0): array([ 6.79053107e-03,  1.47602371e-03, -3.36838257e-02, ...,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.04099637,  0.00805515]), ('mountain bike', 3): array([ 0.00392868,  0.00342776, -0.01479598, ..., -0.00387774,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.06810667, -0.00150155]), ('mountain bike', 5): array([ 0.00693134,  0.01393553, -0.01967798, ...,  0.0122983 ,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m        -0.0284926 , -0.00576641]), ('mountain bike', 7): array([-0.00764953,  0.05922888,  0.04825101, ..., -0.0134859 ,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.00201374, -0.00453843]), ('mountain bike', 12): array([ 0.03795566,  0.04533841,  0.00280493, ..., -0.00344645,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.05257986, -0.00152813]), ('mountain bike', 13): array([ 0.01243439,  0.08863045,  0.01948023, ...,  0.01699589,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.01171652, -0.00204828])} \n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1842: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "\u001b[36m(ClientAppActor pid=2482602)\u001b[0m   self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m /tmp/ray/session_2025-08-16_18-37-22_878768_2478198/runtime_resources/pip/4150a55c15f671ce4c2791881600725157b37fc9/virtualenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:456: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m   opt_res = optimize.minimize(\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m  {('basketball', 0): array([-0.03739622, -0.00411158, -0.00067806, ..., -0.00193778,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.07146897, -0.0121714 ]), ('basketball', 4): array([ 0.03771825, -0.0046272 , -0.0371666 , ...,  0.00357401,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.0196303 , -0.01289586]), ('moving van', 3): array([-0.08252955, -0.01986421,  0.00517902, ..., -0.00826771,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.06502832,  0.0077115 ]), ('moving van', 14): array([-0.03626315,  0.02630419,  0.00927335, ..., -0.01213745,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.00919852, -0.03982089])} \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m \n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m all the related CAV of Class moving van was successfully generated : \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.0286081 , -0.00880425]), ('basketball', 2): array([-0.02357098,  0.02425544, -0.01580898, ..., -0.00662734,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.02259594, -0.0168617 ]), ('basketball', 1): array([-0.00400034, -0.00556237, -0.00783795, ..., -0.00121978,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.03059659, -0.00410574]), ('moving van', 11): array([-0.00196405, -0.0135592 ,  0.00745735, ..., -0.00742467,\n",
      "\u001b[36m(ClientAppActor pid=2482603)\u001b[0m         0.00833809,  0.01042887]), ('moving van', 7): array([ 0.03244943, -0.0194202 , -0.0079429 , ...,  0.00178953,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.06502536,  0.00132673]), ('moving van', 8): array([-0.00618744, -0.00035943, -0.02039356, ..., -0.00620155,\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.0787499 ,  0.01806379]), ('moving van', 13): array([ 0.00288855, -0.02032383, -0.00227057, ..., -0.02300899,\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.02088644, -0.00918027]), ('moving van', 12): array([ 0.00733717, -0.01723241, -0.01228781, ..., -0.00529175,\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.04688967, -0.00546113]), ('moving van', 9): array([ 0.02767643, -0.0223565 , -0.00957366, ...,  0.03886432,\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.03402389, -0.00627204]), ('basketball', 10): array([ 0.00999777,  0.00144792, -0.00801362, ..., -0.00576945,\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.00650519,  0.01022033]), ('basketball', 11): array([-0.00717181, -0.00758908,  0.0508886 , ...,  0.01578842,\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.02936756, -0.01130002]), ('mountain bike', 14): array([0.0094058 , 0.07133331, 0.04146965, ..., 0.00535488, 0.01693267,\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.06543341, -0.00353427]), ('mountain bike', 13): array([-0.01059264,  0.05999139,  0.03189706, ...,  0.02411757,\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         1.92899145e-02, -2.13982739e-02,  1.86951125e-02]), ('mountain bike', 8): array([ 0.00717758, -0.0348178 ,  0.03909295, ..., -0.02023421,\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m         0.03776461, -0.00700463]), ('basketball', 14): array([ 0.0350432 ,  0.00717682, -0.02400191, ...,  0.03859104,\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=2482604)\u001b[0m        -0.05423841,  0.02977708]), ('basketball', 9): array([-0.04001155, -0.02018358, -0.03707447, ..., -0.00060582,\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def precompute_client_data(num_clients=3):\n",
    "    import pickle\n",
    "    import logging\n",
    "    #logging.getLogger('root').setLevel(logging.WARNING)\n",
    "    root_dir = '/gpfs/helios/home/mahmouds/Thesis/data/ILSVRC2012/segmentation'\n",
    "    SAM_transform = transforms.Compose([transforms.Resize((224, 224))])\n",
    "    dino_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    imagenet_dataset = datasets.ImageFolder(root=root_dir, transform=SAM_transform)\n",
    "    \n",
    "   \n",
    "\n",
    "        # Load SAM2 model\n",
    "    sam2_checkpoint = \"/gpfs/helios/home/mahmouds/sam2/checkpoints/sam2.1_hiera_large.pt\"\n",
    "    model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "\n",
    "    assert os.path.exists(sam2_checkpoint), f\"SAM2 checkpoint {sam2_checkpoint} not found.\"\n",
    "\n",
    "    sam2 = build_sam2(model_cfg, sam2_checkpoint, device=device)\n",
    "    dinov2_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').to(device).eval() #ViT-B/32\n",
    "    mask_gen = SAM2AutomaticMaskGenerator(\n",
    "            model=sam2,\n",
    "            predicted_iou_thresh=0.88,\n",
    "            stability_score_thresh=0.8,\n",
    "            box_nms_thresh=0.5,\n",
    "            crop_n_layers=0,\n",
    "            min_mask_region_area=256,\n",
    "            max_num_masks=30\n",
    "        )\n",
    "\n",
    "        # Dataset and segmentation\n",
    "    SAM_transform = transforms.Compose([transforms.Resize((224, 224))])\n",
    "    imagenet_dataset = datasets.ImageFolder(root=root_dir, transform=SAM_transform)\n",
    "    for cid in range(num_clients):\n",
    "        print(f\"🔧 Starting SAM2 segmentation and saving segments with metadata for client {cid} ...\")\n",
    "        #logger.info(f\"Precomputing for client {cid}...\")\n",
    "        segment_root = f'segment_dataset/segments/segments_client_{cid}'\n",
    "        os.makedirs(segment_root, exist_ok=True)\n",
    "        #client_features, client_labels, client_metas = [], [], []\n",
    "        #for img_idx, (image_tensor, label) in tqdm(enumerate(imagenet_dataset), total=len(imagenet_dataset)):\n",
    "        #    if img_idx % num_clients != cid:\n",
    "        #        continue\n",
    "\n",
    "        #    orig_img_path, _ = imagenet_dataset.samples[img_idx]\n",
    "        #    img_pil = Image.open(orig_img_path).convert(\"RGB\")\n",
    "        #    img_np = np.array(img_pil)\n",
    "            \n",
    "        #    try:\n",
    "        #        masks = mask_gen.generate(img_np)\n",
    "        #        if not masks or len(masks) == 0:\n",
    "        #            print(f\"[Client {cid}] ⚠️ No masks returned for image {img_idx}: {orig_img_path}\")\n",
    "        #            continue    \n",
    "        #    except Exception as e:\n",
    "        #        print(f\"[Client {cid}] Segmentation failed on image {orig_img_path}: {e}\")\n",
    "        #        continue\n",
    "\n",
    "        #    segments, scores, bboxes = [], [], []\n",
    "        #    for m in masks:\n",
    "        #        mask = m[\"segmentation\"].astype(bool)\n",
    "        #        seg = img_np.copy()\n",
    "        #        seg[~mask] = 0\n",
    "        #        segments.append(seg)\n",
    "        #        scores.append(m[\"predicted_iou\"])\n",
    "        #        bboxes.append(get_bbox_from_mask(mask))\n",
    "\n",
    "        #    class_name = imagenet_dataset.classes[label]\n",
    "        #    class_dir = os.path.join(segment_root, class_name)\n",
    "\n",
    "        #    save_segments_with_metadata(\n",
    "        #        img_idx, label, segments, scores, bboxes, orig_img_path, class_dir, score_threshold=0.65\n",
    "        #    )\n",
    "\n",
    "        print(f\"[Client {cid}] Segmentation done. Starting feature extraction...\")\n",
    "            \n",
    "        \n",
    "        #segment_dataset = SegmentDataset(segment_root=segment_root, transform=dino_transform)\n",
    "        #print(segment_dataset.get_stats())\n",
    "        #segment_loader = DataLoader(segment_dataset, batch_size=512, shuffle=False, collate_fn=custom_collate)\n",
    "        \n",
    "        #features, labels, metas = extract_features_dinov2(segment_loader, dinov2_model, device)\n",
    "        #print(f\"[Client {cid}] Extracted features: {features.shape}, Labels: {len(labels)}\")\n",
    "        #data = {'features': features, 'labels': labels, 'metas': metas}\n",
    "        #with open(f'segment_dataset/segments/precomputed_client_{cid}.pkl', 'wb') as f:\n",
    "        #        pickle.dump(data, f)\n",
    "        logging.info(f\"Precomputed data saved for client {cid}.\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    dinov2_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14').to(device).eval()\n",
    "    number_of_clusters =15\n",
    "    num_clients = 3\n",
    "    np.random.seed(42)\n",
    "\n",
    "    root_dir_init = '/gpfs/helios/home/mahmouds/Thesis/root/'\n",
    "    def dino_transform():\n",
    "        return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    transform_init = transforms.Compose([transforms.Resize((224, 224))])\n",
    "    dataset_init = datasets.ImageFolder(root=root_dir_init, transform=transform_init)\n",
    "    dino_transform = dino_transform()\n",
    "    \n",
    "    class_to_img_path = defaultdict(list)\n",
    "    for img_idx, (img_tensor, label) in enumerate(dataset_init):\n",
    "        img_path, _ = dataset_init.samples[img_idx]\n",
    "        class_to_img_path[label].append(img_path)\n",
    "    \n",
    "    initial_centroids_per_class = {}\n",
    "    sampled_imgs = []\n",
    "    class_labels = []\n",
    "     #Compute all DINOv2 features per class\n",
    "    initial_centroids_per_class = {}\n",
    "    for class_label, paths in class_to_img_path.items():\n",
    "        img_tensors = []\n",
    "        for img_path in paths:\n",
    "            img_pil = Image.open(img_path).convert(\"RGB\")\n",
    "            img_tensors.append(dino_transform(img_pil))\n",
    "        batch = torch.stack(img_tensors).to(device)\n",
    "        with torch.no_grad():\n",
    "            features = dinov2_model(batch).cpu().numpy()\n",
    "        # Get KMeans++ initial centroids for this class\n",
    "        kmeans = KMeans(n_clusters=number_of_clusters, init='k-means++', random_state=42)\n",
    "        kmeans.fit(features)\n",
    "        initial_centroids_per_class[class_label] = kmeans.cluster_centers_  # shape: (K, D)\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"Computed {number_of_clusters} centroids for class {class_label}\")\n",
    "\n",
    "    print(f\"\\nTotal classes initialized: {len(initial_centroids_per_class)}\")\n",
    "    strategy = FedKMeansStrategy(initial_centroids=initial_centroids_per_class, num_clusters=number_of_clusters, tol=.5)\n",
    "    precompute_client_data(num_clients)\n",
    "    \n",
    "    def client_fn(context):\n",
    "     import pickle\n",
    "     cid = int(context.node_config['partition-id'])\n",
    "     print(f\"[Client {cid}] Starting initialization...\")\n",
    "\n",
    "     try:\n",
    "        print(f\"[Client {cid}] Attempting to load pickle file...\") \n",
    "        with open(f'segment_dataset/segments/precomputed_client_{cid}.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(f\"[Client {cid}] Pickle file loaded successfully\")\n",
    "        features = data['features']\n",
    "        labels = data['labels']\n",
    "        metas = data['metas']\n",
    "        print(f\"[Client {cid}] Data extracted: features={features.shape}, labels={len(labels)}, metas={len(metas)}\")\n",
    "        client = ThesisKMeansClient(cid,features, labels, metas, device)\n",
    "        print(f\"[Client {cid}] ThesisKMeansClient created successfully\")\n",
    "        return client.to_client()\n",
    "     except Exception as e:\n",
    "        print(f\"[Client {self.cid}] failed: {e}\")\n",
    "        raise e\n",
    "\n",
    "    fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=num_clients,\n",
    "        config=fl.server.ServerConfig(num_rounds=50),\n",
    "        strategy=strategy,\n",
    "        client_resources={\"num_cpus\": 4, \"num_gpus\": 0.25},\n",
    "        ray_init_args={\"object_store_memory\": 5 * 1024 * 1024 * 1024,  # 5GiB\n",
    "            \"runtime_env\": {\"pip\": [\n",
    "    \"torch\", \"torchvision\", \"flwr\", \"xformers\", \"umap-learn\", \n",
    "            \"kneed\", \"scikit-learn\", \"opencv-python-headless\", \"clip\", \n",
    "            \"ftfy\", \"regex\", \"tqdm\", \"Pillow\"\n",
    "]}}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68be64d-fe7c-4ead-8a8f-ea08b50bda26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis3.12",
   "language": "python",
   "name": "thesis3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
